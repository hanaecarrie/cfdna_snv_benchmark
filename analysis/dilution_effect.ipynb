{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pysam\n",
    "from collections import Counter\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import io\n",
    "from pysam import VariantFile\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab20 = cm.get_cmap('tab10', 8)\n",
    "newcmap_list = []\n",
    "for i in range(4):\n",
    "    newcmap_list.append(tab20.colors[i])\n",
    "for i in range(4):\n",
    "    newcmap_list.append(np.array(list(tab20.colors[i][:-1]) +[0.3]))\n",
    "\n",
    "newcmap = ListedColormap(newcmap_list, name='newcmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = [l for l in f if not l.startswith('##')]\n",
    "    res = pd.read_csv(\n",
    "        io.StringIO(''.join(lines)),\n",
    "        dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str,\n",
    "               'QUAL': str, 'FILTER': str, 'INFO': str},\n",
    "        sep='\\t'\n",
    "    ).rename(columns={'#CHROM': 'CHROM'})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilution effect on 809_110914\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = lambda x: pd.Series(x.split('CALLERS=')[1].split(';')[0])\n",
    "vcf_pd_0 = read_vcf(\"../data/2015-07-31_CRC-809_110914-filter-1-0/CRC-809_110914-filter-1-0-ensemble-annotated.vcf\")\n",
    "vcf_pd_1 = read_vcf(\"../data/2015-07-31_CRC-809_110914-filter-05-05/CRC-809_110914-filter-05-05-ensemble-annotated.vcf\")\n",
    "vcf_pd_2 = read_vcf(\"../data/2015-07-31_CRC-809_110914-filter-005-095/CRC-809_110914-filter-005-095-ensemble-annotated.vcf\")\n",
    "vcf_pd_3 = read_vcf(\"../data/2015-07-31_CRC-809_110914-filter-001-099/CRC-809_110914-filter-001-099-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_0['INFO'] = vcf_pd_0['INFO'].apply(foo)\n",
    "vcf_pd_0['freebayes'] = vcf_pd_0['INFO'].str.contains('freebayes')\n",
    "vcf_pd_0['vardict'] = vcf_pd_0['INFO'].str.contains('vardict')\n",
    "vcf_pd_0['varscan'] = vcf_pd_0['INFO'].str.contains('varscan')\n",
    "vcf_pd_0['mutect2'] = vcf_pd_0['INFO'].str.contains('mutect2')\n",
    "vcf_pd_0['strelka2'] = vcf_pd_0['INFO'].str.contains('strelka2')\n",
    "vcf_pd_0.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_1['INFO'] = vcf_pd_1['INFO'].apply(foo)\n",
    "vcf_pd_1['freebayes'] = vcf_pd_1['INFO'].str.contains('freebayes')\n",
    "vcf_pd_1['vardict'] = vcf_pd_1['INFO'].str.contains('vardict')\n",
    "vcf_pd_1['varscan'] = vcf_pd_1['INFO'].str.contains('varscan')\n",
    "vcf_pd_1['mutect2'] = vcf_pd_1['INFO'].str.contains('mutect2')\n",
    "vcf_pd_1['strelka2'] = vcf_pd_1['INFO'].str.contains('strelka2')\n",
    "vcf_pd_1.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_2['INFO'] = vcf_pd_2['INFO'].apply(foo)\n",
    "vcf_pd_2['freebayes'] = vcf_pd_2['INFO'].str.contains('freebayes')\n",
    "vcf_pd_2['vardict'] = vcf_pd_2['INFO'].str.contains('vardict')\n",
    "vcf_pd_2['varscan'] = vcf_pd_2['INFO'].str.contains('varscan')\n",
    "vcf_pd_2['mutect2'] = vcf_pd_2['INFO'].str.contains('mutect2')\n",
    "vcf_pd_2['strelka2'] = vcf_pd_2['INFO'].str.contains('strelka2')\n",
    "vcf_pd_2.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_3['INFO'] = vcf_pd_3['INFO'].apply(foo)\n",
    "vcf_pd_3['freebayes'] = vcf_pd_3['INFO'].str.contains('freebayes')\n",
    "vcf_pd_3['vardict'] = vcf_pd_3['INFO'].str.contains('vardict')\n",
    "vcf_pd_3['varscan'] = vcf_pd_3['INFO'].str.contains('varscan')\n",
    "vcf_pd_3['mutect2'] = vcf_pd_3['INFO'].str.contains('mutect2')\n",
    "vcf_pd_3['strelka2'] = vcf_pd_3['INFO'].str.contains('strelka2')\n",
    "vcf_pd_3.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_0['SNV callers'] = vcf_pd_0['freebayes'].map(str) + '_' + vcf_pd_0['vardict'].map(str) +  '_' + vcf_pd_0['varscan'].map(str)\n",
    "vcf_pd_1['SNV callers'] = vcf_pd_1['freebayes'].map(str) + '_' + vcf_pd_1['vardict'].map(str) +  '_' + vcf_pd_1['varscan'].map(str)\n",
    "vcf_pd_2['SNV callers'] = vcf_pd_2['freebayes'].map(str) + '_' + vcf_pd_2['vardict'].map(str) +  '_' + vcf_pd_2['varscan'].map(str)\n",
    "vcf_pd_3['SNV callers'] = vcf_pd_3['freebayes'].map(str) + '_' + vcf_pd_3['vardict'].map(str) +  '_' + vcf_pd_3['varscan'].map(str)\n",
    "\n",
    "sample_0 = vcf_pd_0[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_0['CHROM_POS'] = sample_0['CHROM'].astype('str').str.cat(sample_0['POS'].astype('str'),sep=\"_\")\n",
    "sample_0.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_1 = vcf_pd_1[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_1['CHROM_POS'] = sample_1['CHROM'].astype('str').str.cat(sample_1['POS'].astype('str'),sep=\"_\")\n",
    "sample_1.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_2 = vcf_pd_2[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_2['CHROM_POS'] = sample_2['CHROM'].astype('str').str.cat(sample_2['POS'].astype('str'),sep=\"_\")\n",
    "sample_2.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3 = vcf_pd_3[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_3['CHROM_POS'] = sample_3['CHROM'].astype('str').str.cat(sample_3['POS'].astype('str'),sep=\"_\")\n",
    "sample_3.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimated tumor burden of mixed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tf = {\n",
    "    'sample_0': 0.47,\n",
    "    'sample_1': float(list(pd.read_csv(\"../data/2015-07-31_CRC-809_110914-filter-05-05/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_2': float(list(pd.read_csv(\"../data/2015-07-31_CRC-809_110914-filter-005-095/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_3': float(list(pd.read_csv(\"../data/2015-07-31_CRC-809_110914-filter-001-099/estimated_tf.txt\").columns)[0]),\n",
    "}\n",
    "\n",
    "print(samples_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of detections detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbersnvs_pd = pd.DataFrame.empty\n",
    "\n",
    "for si, s in enumerate([sample_0, sample_1, sample_2, sample_3]):\n",
    "    nb_snv = []\n",
    "    for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "        if si == 4:\n",
    "            si = 't'\n",
    "       # print('sample '+ str(si) + ': ', method, s[s[method] == True].shape[0])\n",
    "        nb_snv.append(s[s[method] == True].shape[0])\n",
    "    if si == 0:\n",
    "        numbersnvs_pd = pd.DataFrame.from_dict({'sample_'+ str(si): nb_snv}).T\n",
    "        numbersnvs_pd.columns = ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']\n",
    "    else:\n",
    "        numbersnvs_pd.loc['sample_'+ str(si)] = nb_snv\n",
    "    numbersnvs_pd = numbersnvs_pd.rename(index=samples_tf)\n",
    "\n",
    "numbersnvs_pd.plot(style='.-', logx=True, xlim=(10e-1, 10e-4))\n",
    "        \n",
    "numbersnvs_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]]\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]]\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]]\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]]\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd_methods[['sample_0', 'caller']]\n",
    "y_true.index.name = 'CHROM_POS'\n",
    "y_true = y_true.groupby(['CHROM_POS'])['sample_0'].sum()\n",
    "y_true[y_true == 1] = 0\n",
    "y_true = y_true.astype(bool)\n",
    "print(y_true.shape[0])\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "    \n",
    "    y_1 = pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_1 = y_1.fillna(False)\n",
    "    y_2 = pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_2 = y_2.fillna(False)\n",
    "    y_3 = pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_3 = y_3.fillna(False)\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true.values, y_1.values),\n",
    "                      precision_score(y_true.values, y_2.values),\n",
    "                      precision_score(y_true.values, y_3.values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true.values, y_1.values),\n",
    "                      recall_score(y_true.values, y_2.values),\n",
    "                      recall_score(y_true.values, y_3.values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "color_list = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "\n",
    "for mi, method in enumerate(['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']):\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]]\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]]\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]]\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]]\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "fig, axs = plt.subplots(3,2,figsize=(10, 15))\n",
    "fig.suptitle('Precision-Recall curves')\n",
    "\n",
    "y_true = pd_methods[['sample_0', 'caller']]\n",
    "y_true.index.name = 'CHROM_POS'\n",
    "y_true = y_true.groupby(['CHROM_POS'])['sample_0'].sum()\n",
    "y_true[y_true <= 2] = 0\n",
    "y_true = y_true.astype(bool)\n",
    "print(y_true.shape[0])\n",
    "\n",
    "for mi, method in enumerate(['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']):\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    #y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "    y_0 = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_0 = y_0.fillna(False)\n",
    "    y_1 = pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_1 = y_1.fillna(False)\n",
    "    y_2 = pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_2 = y_2.fillna(False)\n",
    "    y_3 = pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_3 = y_3.fillna(False)\n",
    "\n",
    "    res_df['AUPCR'] = [average_precision_score(y_true, y_0),\n",
    "                      average_precision_score(y_true, y_1),\n",
    "                      average_precision_score(y_true, y_2),\n",
    "                      average_precision_score(y_true, y_3),\n",
    "                     ]\n",
    "    res_df['caller'] = method\n",
    " \n",
    "    # Plot Precision-Recall curve\n",
    "    alpha_list = [1, .75, .5, .2]\n",
    "    for i in range(0,4):\n",
    "        y_i = pd_methods[pd_methods['caller'] == method]['sample_'+str(i)].astype(bool).reindex(y_true.index).squeeze()\n",
    "        y_i = y_i.fillna(False)\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_i)\n",
    "        axs[mi//2, mi%2].plot(recall, precision, 'o-',\n",
    "                              label='tf='+str(res_df['tumor burden'].loc['sample_'+str(i)])+ ', AP='+str(round(average_precision_score(y_true, y_i), 2)),\n",
    "                              c=color_list[mi], alpha=alpha_list[i])\n",
    "    axs[mi//2, mi%2].set_xlabel('Recall')\n",
    "    axs[mi//2, mi%2].set_ylabel('Precision')\n",
    "    axs[mi//2, mi%2].set_ylim([0.0, 1.05])\n",
    "    axs[mi//2, mi%2].set_xlim([0.0, 1.05])\n",
    "    axs[mi//2, mi%2].set_title(method)\n",
    "    axs[mi//2, mi%2].legend()\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "plt.show()\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"AUPCR\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 liquid biopsy samples as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_pd_0_bis = read_vcf(\"../data/2015-07-31_CRC-809_030915-filter-1-0/CRC-809_030915-filter-1-0-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_0_bis['INFO'] = vcf_pd_0_bis['INFO'].apply(foo)\n",
    "vcf_pd_0_bis['freebayes'] = vcf_pd_0_bis['INFO'].str.contains('freebayes')\n",
    "vcf_pd_0_bis['vardict'] = vcf_pd_0_bis['INFO'].str.contains('vardict')\n",
    "vcf_pd_0_bis['varscan'] = vcf_pd_0_bis['INFO'].str.contains('varscan')\n",
    "vcf_pd_0_bis['mutect2'] = vcf_pd_0_bis['INFO'].str.contains('mutect2')\n",
    "vcf_pd_0_bis['strelka2'] = vcf_pd_0_bis['INFO'].str.contains('strelka2')\n",
    "vcf_pd_0_bis.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_0_bis['SNV callers'] = vcf_pd_0_bis['freebayes'].map(str) + '_' + vcf_pd_0_bis['vardict'].map(str) +  '_' + vcf_pd_0_bis['varscan'].map(str)\n",
    "\n",
    "sample_0_bis = vcf_pd_0_bis[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_0_bis['CHROM_POS'] = sample_0_bis['CHROM'].astype('str').str.cat(sample_0_bis['POS'].astype('str'),sep=\"_\")\n",
    "sample_0_bis.set_index('CHROM_POS', inplace = True)\n",
    "sample_0_bis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample0 = sample_0.copy()\n",
    "sample0['date'] = '110914'\n",
    "sample0bis = sample_0_bis.copy()\n",
    "sample0bis['date'] = '030915'\n",
    "sample_ref = pd.concat([sample0, sample0bis], join='inner')\n",
    "l1 = list(sample_ref[sample_ref['date'] == '110914'].index)\n",
    "l2 = list(sample_ref[sample_ref['date'] == '030915'].index)\n",
    "print(len(l1), len(l2))\n",
    "print(len(list(set(set(l1) ^ set(l2)))))\n",
    "print(len(list(set(set(l1) & set(l2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ref.loc[list(set(set(l1) & set(l2)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tumor reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = lambda x: pd.Series(x.split('CALLERS=')[1].split(';')[0])\n",
    "vcf_pd_t = read_vcf(\"../data/2015-07-31_NCC_CRC-809_290714-T1W/NCC_CRC-809_290714-T1W-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_t['INFO'] = vcf_pd_t['INFO'].apply(foo)\n",
    "vcf_pd_t['freebayes'] = vcf_pd_t['INFO'].str.contains('freebayes')\n",
    "vcf_pd_t['vardict'] = vcf_pd_t['INFO'].str.contains('vardict')\n",
    "vcf_pd_t['varscan'] = vcf_pd_t['INFO'].str.contains('varscan')\n",
    "vcf_pd_t['mutect2'] = vcf_pd_t['INFO'].str.contains('mutect2')\n",
    "vcf_pd_t['strelka2'] = vcf_pd_t['INFO'].str.contains('strelka2')\n",
    "vcf_pd_t.drop('INFO', axis=1)\n",
    "\n",
    "\n",
    "vcf_pd_t['SNV callers'] = vcf_pd_t['freebayes'].map(str) + '_' + vcf_pd_t['vardict'].map(str) +  '_' + vcf_pd_t['varscan'].map(str)\n",
    "\n",
    "sample_t = vcf_pd_t[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_t['CHROM_POS'] = sample_t['CHROM'].astype('str').str.cat(sample_t['POS'].astype('str'),sep=\"_\")\n",
    "sample_t.set_index('CHROM_POS', inplace = True)\n",
    "sample_t = sample_t[sample_t['CHROM'] == '22']\n",
    "sample_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(sample_t.index)\n",
    "l2 = list(sample_0.index)\n",
    "print(len(l1), len(l2))\n",
    "print(len(list(set(set(l1) & set(l2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    st = sample_t[['REF', 'ALT', 'QUAL', method]]\n",
    "    st.rename(columns = {method:'sample_t'},  inplace = True)\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]]\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]]\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]]\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]]\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([st, s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_t', 'sample_t', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_t', 'sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_t', 'sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_t'] + pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_t', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_t'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [\n",
    "        precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values),\n",
    "        precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "        precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "        precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [\n",
    "        recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values),\n",
    "        recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "        recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "        recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Histograms of true allele frequencies in each tumor sample. Note how increasing admixture increases the prevalence of low- frequency variants.\n",
    "- Benchmarking results for germline SNVs\n",
    "- Benchmarking results for somatic SNVs on exome data.\n",
    "- averaged over the four replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add fake mutations on healthy mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilution effect on 986_100215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = lambda x: pd.Series(x.split('CALLERS=')[1].split(';')[0])\n",
    "vcf_pd_0 = read_vcf(\"../data/2015-07-31_CRC-986_100215-filter-1-0/CRC-986_100215-filter-1-0-ensemble-annotated.vcf\")\n",
    "vcf_pd_1 = read_vcf(\"../data/2015-07-31_CRC-986_100215-filter-05-05/CRC-986_100215-filter-05-05-ensemble-annotated.vcf\")\n",
    "vcf_pd_2 = read_vcf(\"../data/2015-07-31_CRC-986_100215-filter-005-095/CRC-986_100215-filter-005-095-ensemble-annotated.vcf\")\n",
    "vcf_pd_3 = read_vcf(\"../data/2015-07-31_CRC-986_100215-filter-001-099/CRC-986_100215-filter-001-099-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_0['INFO'] = vcf_pd_0['INFO'].apply(foo)\n",
    "vcf_pd_0['freebayes'] = vcf_pd_0['INFO'].str.contains('freebayes')\n",
    "vcf_pd_0['vardict'] = vcf_pd_0['INFO'].str.contains('vardict')\n",
    "vcf_pd_0['varscan'] = vcf_pd_0['INFO'].str.contains('varscan')\n",
    "vcf_pd_0['mutect2'] = vcf_pd_0['INFO'].str.contains('mutect2')\n",
    "vcf_pd_0['strelka2'] = vcf_pd_0['INFO'].str.contains('strelka2')\n",
    "vcf_pd_0.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_1['INFO'] = vcf_pd_1['INFO'].apply(foo)\n",
    "vcf_pd_1['freebayes'] = vcf_pd_1['INFO'].str.contains('freebayes')\n",
    "vcf_pd_1['vardict'] = vcf_pd_1['INFO'].str.contains('vardict')\n",
    "vcf_pd_1['varscan'] = vcf_pd_1['INFO'].str.contains('varscan')\n",
    "vcf_pd_1['mutect2'] = vcf_pd_1['INFO'].str.contains('mutect2')\n",
    "vcf_pd_1['strelka2'] = vcf_pd_1['INFO'].str.contains('strelka2')\n",
    "vcf_pd_1.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_2['INFO'] = vcf_pd_2['INFO'].apply(foo)\n",
    "vcf_pd_2['freebayes'] = vcf_pd_2['INFO'].str.contains('freebayes')\n",
    "vcf_pd_2['vardict'] = vcf_pd_2['INFO'].str.contains('vardict')\n",
    "vcf_pd_2['varscan'] = vcf_pd_2['INFO'].str.contains('varscan')\n",
    "vcf_pd_2['mutect2'] = vcf_pd_2['INFO'].str.contains('mutect2')\n",
    "vcf_pd_2['strelka2'] = vcf_pd_2['INFO'].str.contains('strelka2')\n",
    "vcf_pd_2.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_3['INFO'] = vcf_pd_3['INFO'].apply(foo)\n",
    "vcf_pd_3['freebayes'] = vcf_pd_3['INFO'].str.contains('freebayes')\n",
    "vcf_pd_3['vardict'] = vcf_pd_3['INFO'].str.contains('vardict')\n",
    "vcf_pd_3['varscan'] = vcf_pd_3['INFO'].str.contains('varscan')\n",
    "vcf_pd_3['mutect2'] = vcf_pd_3['INFO'].str.contains('mutect2')\n",
    "vcf_pd_3['strelka2'] = vcf_pd_3['INFO'].str.contains('strelka2')\n",
    "vcf_pd_3.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_0['SNV callers'] = vcf_pd_0['freebayes'].map(str) + '_' + vcf_pd_0['vardict'].map(str) +  '_' + vcf_pd_0['varscan'].map(str)\n",
    "vcf_pd_1['SNV callers'] = vcf_pd_1['freebayes'].map(str) + '_' + vcf_pd_1['vardict'].map(str) +  '_' + vcf_pd_1['varscan'].map(str)\n",
    "vcf_pd_2['SNV callers'] = vcf_pd_2['freebayes'].map(str) + '_' + vcf_pd_2['vardict'].map(str) +  '_' + vcf_pd_2['varscan'].map(str)\n",
    "vcf_pd_3['SNV callers'] = vcf_pd_3['freebayes'].map(str) + '_' + vcf_pd_3['vardict'].map(str) +  '_' + vcf_pd_3['varscan'].map(str)\n",
    "\n",
    "sample_0 = vcf_pd_0[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_0['CHROM_POS'] = sample_0['CHROM'].astype('str').str.cat(sample_0['POS'].astype('str'),sep=\"_\")\n",
    "sample_0.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_1 = vcf_pd_1[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_1['CHROM_POS'] = sample_1['CHROM'].astype('str').str.cat(sample_1['POS'].astype('str'),sep=\"_\")\n",
    "sample_1.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_2 = vcf_pd_2[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_2['CHROM_POS'] = sample_2['CHROM'].astype('str').str.cat(sample_2['POS'].astype('str'),sep=\"_\")\n",
    "sample_2.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3 = vcf_pd_3[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_3['CHROM_POS'] = sample_3['CHROM'].astype('str').str.cat(sample_3['POS'].astype('str'),sep=\"_\")\n",
    "sample_3.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tf = {\n",
    "    'sample_0': 0.42,\n",
    "    'sample_1': float(list(pd.read_csv(\"../data/2015-07-31_CRC-986_100215-filter-05-05/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_2': float(list(pd.read_csv(\"../data/2015-07-31_CRC-986_100215-filter-005-095/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_3': float(list(pd.read_csv(\"../data/2015-07-31_CRC-986_100215-filter-001-099/estimated_tf.txt\").columns)[0]),\n",
    "}\n",
    "\n",
    "print(samples_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbersnvs_pd = pd.DataFrame.empty\n",
    "\n",
    "for si, s in enumerate([sample_0, sample_1, sample_2, sample_3]):\n",
    "    nb_snv = []\n",
    "    for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "        if si == 4:\n",
    "            si = 't'\n",
    "       # print('sample '+ str(si) + ': ', method, s[s[method] == True].shape[0])\n",
    "        nb_snv.append(s[s[method] == True].shape[0])\n",
    "    if si == 0:\n",
    "        numbersnvs_pd = pd.DataFrame.from_dict({'sample_'+ str(si): nb_snv}).T\n",
    "        numbersnvs_pd.columns = ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']\n",
    "    else:\n",
    "        numbersnvs_pd.loc['sample_'+ str(si)] = nb_snv\n",
    "\n",
    "numbersnvs_pd.plot(style='.-')\n",
    "        \n",
    "numbersnvs_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]]\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]]\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]]\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]]\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd_methods[['sample_0', 'caller']]\n",
    "y_true.index.name = 'CHROM_POS'\n",
    "y_true = y_true.groupby(['CHROM_POS'])['sample_0'].sum()\n",
    "y_true[y_true == 1] = 0\n",
    "y_true = y_true.astype(bool)\n",
    "print(y_true.shape[0])\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "    \n",
    "    y_1 = pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_1 = y_1.fillna(False)\n",
    "    y_2 = pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_2 = y_2.fillna(False)\n",
    "    y_3 = pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_3 = y_3.fillna(False)\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true.values, y_1.values),\n",
    "                      precision_score(y_true.values, y_2.values),\n",
    "                      precision_score(y_true.values, y_3.values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true.values, y_1.values),\n",
    "                      recall_score(y_true.values, y_2.values),\n",
    "                      recall_score(y_true.values, y_3.values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1]\n",
    "                        if len(list(np.unique([i for i in list(ai) if str(i) != 'nan']))) else 'nan'\n",
    "                        for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1]\n",
    "                        if len(list(np.unique([i for i in list(ai) if str(i) != 'nan']))) else 'nan'\n",
    "                        for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
