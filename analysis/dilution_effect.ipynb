{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pysam\n",
    "from collections import Counter\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import io\n",
    "from pysam import VariantFile\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab20 = cm.get_cmap('tab10', 8)\n",
    "newcmap_list = []\n",
    "for i in range(4):\n",
    "    newcmap_list.append(tab20.colors[i])\n",
    "for i in range(4):\n",
    "    newcmap_list.append(np.array(list(tab20.colors[i][:-1]) +[0.3]))\n",
    "\n",
    "newcmap = ListedColormap(newcmap_list, name='newcmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = [l for l in f if not l.startswith('##')]\n",
    "    res = pd.read_csv(\n",
    "        io.StringIO(''.join(lines)),\n",
    "        dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str,\n",
    "               'QUAL': str, 'FILTER': str, 'INFO': str},\n",
    "        sep='\\t'\n",
    "    ).rename(columns={'#CHROM': 'CHROM'})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilution effect on 809_110914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   },
   "source": [
    "foo = lambda x: pd.Series(x.split('CALLERS=')[1].split(';')[0])\n",
    "vcf_pd_0 = read_vcf(\"../data/2015-07-31_CRC-809_110914-filter-1-0/CRC-809_110914-filter-1-0-ensemble-annotated.vcf\")\n",
    "vcf_pd_1 = read_vcf(\"../data/2015-07-31_CRC-809_110914-filter-05-05/CRC-809_110914-filter-05-05-ensemble-annotated.vcf\")\n",
    "vcf_pd_2 = read_vcf(\"../data/2015-07-31_CRC-809_110914-filter-005-095/CRC-809_110914-filter-005-095-ensemble-annotated.vcf\")\n",
    "vcf_pd_3 = read_vcf(\"../data/2015-07-31_CRC-809_110914-filter-001-099/CRC-809_110914-filter-001-099-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_0['INFO'] = vcf_pd_0['INFO'].apply(foo)\n",
    "vcf_pd_0['freebayes'] = vcf_pd_0['INFO'].str.contains('freebayes')\n",
    "vcf_pd_0['vardict'] = vcf_pd_0['INFO'].str.contains('vardict')\n",
    "vcf_pd_0['varscan'] = vcf_pd_0['INFO'].str.contains('varscan')\n",
    "vcf_pd_0['mutect2'] = vcf_pd_0['INFO'].str.contains('mutect2')\n",
    "vcf_pd_0['strelka2'] = vcf_pd_0['INFO'].str.contains('strelka2')\n",
    "vcf_pd_0.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_1['INFO'] = vcf_pd_1['INFO'].apply(foo)\n",
    "vcf_pd_1['freebayes'] = vcf_pd_1['INFO'].str.contains('freebayes')\n",
    "vcf_pd_1['vardict'] = vcf_pd_1['INFO'].str.contains('vardict')\n",
    "vcf_pd_1['varscan'] = vcf_pd_1['INFO'].str.contains('varscan')\n",
    "vcf_pd_1['mutect2'] = vcf_pd_1['INFO'].str.contains('mutect2')\n",
    "vcf_pd_1['strelka2'] = vcf_pd_1['INFO'].str.contains('strelka2')\n",
    "vcf_pd_1.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_2['INFO'] = vcf_pd_2['INFO'].apply(foo)\n",
    "vcf_pd_2['freebayes'] = vcf_pd_2['INFO'].str.contains('freebayes')\n",
    "vcf_pd_2['vardict'] = vcf_pd_2['INFO'].str.contains('vardict')\n",
    "vcf_pd_2['varscan'] = vcf_pd_2['INFO'].str.contains('varscan')\n",
    "vcf_pd_2['mutect2'] = vcf_pd_2['INFO'].str.contains('mutect2')\n",
    "vcf_pd_2['strelka2'] = vcf_pd_2['INFO'].str.contains('strelka2')\n",
    "vcf_pd_2.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_3['INFO'] = vcf_pd_3['INFO'].apply(foo)\n",
    "vcf_pd_3['freebayes'] = vcf_pd_3['INFO'].str.contains('freebayes')\n",
    "vcf_pd_3['vardict'] = vcf_pd_3['INFO'].str.contains('vardict')\n",
    "vcf_pd_3['varscan'] = vcf_pd_3['INFO'].str.contains('varscan')\n",
    "vcf_pd_3['mutect2'] = vcf_pd_3['INFO'].str.contains('mutect2')\n",
    "vcf_pd_3['strelka2'] = vcf_pd_3['INFO'].str.contains('strelka2')\n",
    "vcf_pd_3.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_0['SNV callers'] = vcf_pd_0['freebayes'].map(str) + '_' + vcf_pd_0['vardict'].map(str) +  '_' + vcf_pd_0['varscan'].map(str)\n",
    "vcf_pd_1['SNV callers'] = vcf_pd_1['freebayes'].map(str) + '_' + vcf_pd_1['vardict'].map(str) +  '_' + vcf_pd_1['varscan'].map(str)\n",
    "vcf_pd_2['SNV callers'] = vcf_pd_2['freebayes'].map(str) + '_' + vcf_pd_2['vardict'].map(str) +  '_' + vcf_pd_2['varscan'].map(str)\n",
    "vcf_pd_3['SNV callers'] = vcf_pd_3['freebayes'].map(str) + '_' + vcf_pd_3['vardict'].map(str) +  '_' + vcf_pd_3['varscan'].map(str)\n",
    "\n",
    "sample_0 = vcf_pd_0[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_0['CHROM_POS'] = sample_0['CHROM'].astype('str').str.cat(sample_0['POS'].astype('str'),sep=\"_\")\n",
    "sample_0.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_1 = vcf_pd_1[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_1['CHROM_POS'] = sample_1['CHROM'].astype('str').str.cat(sample_1['POS'].astype('str'),sep=\"_\")\n",
    "sample_1.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_2 = vcf_pd_2[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_2['CHROM_POS'] = sample_2['CHROM'].astype('str').str.cat(sample_2['POS'].astype('str'),sep=\"_\")\n",
    "sample_2.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3 = vcf_pd_3[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_3['CHROM_POS'] = sample_3['CHROM'].astype('str').str.cat(sample_3['POS'].astype('str'),sep=\"_\")\n",
    "sample_3.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimated tumor burden of mixed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tf = {\n",
    "    'sample_0': 0.47,\n",
    "    'sample_1': float(list(pd.read_csv(\"../data/2015-07-31_CRC-809_110914-filter-05-05/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_2': float(list(pd.read_csv(\"../data/2015-07-31_CRC-809_110914-filter-005-095/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_3': float(list(pd.read_csv(\"../data/2015-07-31_CRC-809_110914-filter-001-099/estimated_tf.txt\").columns)[0]),\n",
    "}\n",
    "\n",
    "print(samples_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single method comparison w.r.t dilution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = sample_0[['REF', 'ALT', 'QUAL', 'freebayes']]\n",
    "s0.rename(columns = {'freebayes':'sample_0'},  inplace = True)\n",
    "s1 = sample_1[['REF', 'ALT', 'QUAL', 'freebayes']]\n",
    "s1.rename(columns = {'freebayes':'sample_1'},  inplace = True)\n",
    "s2 = sample_2[['REF', 'ALT', 'QUAL', 'freebayes']]\n",
    "s2.rename(columns = {'freebayes':'sample_2'},  inplace = True)\n",
    "s3 = sample_3[['REF', 'ALT', 'QUAL', 'freebayes']]\n",
    "s3.rename(columns = {'freebayes':'sample_3'},  inplace = True)\n",
    "\n",
    "print(s0.shape[0] + s1.shape[0] + s2.shape[0] + s3.shape[0])\n",
    "pd_freebayes = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "print(pd_freebayes.shape[0])\n",
    "\n",
    "pd_freebayes[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_freebayes[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "pd_freebayes.drop(pd_freebayes[pd_freebayes['sample_0'] + pd_freebayes['sample_1'] + pd_freebayes['sample_2'] + pd_freebayes['sample_3'] == False].index, axis=0, inplace=True)\n",
    "\n",
    "### check for disagrement about the mutation type ###\n",
    "for index, row in pd_freebayes[['REF']].iterrows():\n",
    "    if len(np.unique((row.dropna().values))) > 1:\n",
    "        print(index)\n",
    "        print(row)\n",
    "        \n",
    "# here 1 locus with disagreement 22_24072091 GT -> G (sample 1) or G -> GT (sample 2 and sample 3)\n",
    "# but sample_1 has False detection\n",
    "# print(pd_freebayes.loc[['22_24072091']])\n",
    "\n",
    "for index, row in pd_freebayes[['ALT']].iterrows():\n",
    "    if len(np.unique((row.dropna().values))) > 1:\n",
    "        print(index)\n",
    "        print(row)\n",
    "        \n",
    "pd_freebayes['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_freebayes['REF'].values)]\n",
    "pd_freebayes['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_freebayes['ALT'].values)]\n",
    "pd_freebayes = pd_freebayes.T.drop_duplicates().T\n",
    "pd_freebayes.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "pd_freebayes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_freebayes.groupby(['sample_0', 'sample_1', 'sample_2', 'sample_3']).size()\n",
    "for qual in ['QUAL_0', 'QUAL_1', 'QUAL_2', 'QUAL_3']:\n",
    "    print('#############')\n",
    "    print(qual)\n",
    "    print(pd_freebayes[(pd_freebayes[qual].astype(float) > 10)].groupby(['sample_0', 'sample_1', 'sample_2', 'sample_3']).size())\n",
    "    \n",
    "print(pd_freebayes[(pd_freebayes['QUAL_0'].astype(float) < 10) & (pd_freebayes['sample_0'] == True)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality\n",
    "aux  = pd_freebayes['sample_0'].map(str) + '_' + pd_freebayes['sample_1'].map(str) + '_' + pd_freebayes['sample_2'].map(str) +  '_' + pd_freebayes['sample_3'].map(str)\n",
    "pd_freebayes_quality = pd_freebayes.copy()\n",
    "pd_freebayes_quality.reset_index(inplace=True)\n",
    "pd_freebayes_quality = pd.melt(pd_freebayes_quality, id_vars =['index'], value_vars =['QUAL_0', 'QUAL_1', 'QUAL_2', 'QUAL_3'])\n",
    "pd_freebayes_quality.set_index('index', inplace=True)\n",
    "pd_freebayes_quality['value'] = pd_freebayes_quality['value'].astype(float)\n",
    "pd_freebayes_quality['SNV calling'] = aux\n",
    "plt.figure(figsize=(35, 6))\n",
    "sns.boxplot(y=\"value\", x=\"SNV calling\", hue='variable', data=pd_freebayes_quality[pd_freebayes_quality['value'] < 200], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd_freebayes['sample_2'].map(str) +  '_' + pd_freebayes['sample_3'].map(str)\n",
    "df_plot = pd_freebayes.copy()\n",
    "df_plot = df_plot.rename({'sample_1': 'SNVs detected in s1'}, axis=1)\n",
    "df_plot['SNV calling'] = aux\n",
    "df_plot = df_plot.groupby(['SNVs detected in s1', 'SNV calling']).size().reset_index().pivot(columns='SNV calling', index='SNVs detected in s1', values=0)\n",
    "df_plot['detected only in s2 or in s3'] = df_plot['False_True'] + df_plot['True_False']\n",
    "df_plot = df_plot.rename({'False_False': 'detected in s1 only', 'True_True': 'detected in both s2 and s3',}, axis=1)\n",
    "df_plot = df_plot[['detected in s1 only', 'detected only in s2 or in s3', 'detected in both s2 and s3']]\n",
    "df_plot.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "df_plot\n",
    "\n",
    "aux = pd_freebayes['sample_2'].map(str) +  '_' + pd_freebayes['sample_3'].map(str)\n",
    "df_plot = pd_freebayes.copy()\n",
    "df_plot = df_plot.rename({'sample_1': 'SNVs detected in s1'}, axis=1)\n",
    "df_plot['SNV calling'] = aux\n",
    "df_plot = df_plot.groupby(['SNVs detected in s1', 'SNV calling']).size().reset_index().pivot(columns='SNV calling', index='SNVs detected in s1', values=0)\n",
    "df_plot = df_plot.rename({'False_False': 'detected in s1 only', 'True_True': 'detected in both s2 and s3',\n",
    "                         'False_True': 'detected in s3 only', 'True_False': 'detected in s2 only'}, axis=1)\n",
    "df_plot.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_freebayes[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_freebayes[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "pd_freebayes.drop(pd_freebayes[pd_freebayes['sample_0'] + pd_freebayes['sample_1'] + pd_freebayes['sample_2'] + pd_freebayes['sample_3'] == False].index, axis=0, inplace=True)\n",
    "#pd_freebayes = pd_freebayes[pd_freebayes['QUAL'].astype(float) > 10]\n",
    "pd_freebayes[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "\n",
    "res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "y_true = pd_freebayes['sample_0'].astype(bool).values\n",
    "\n",
    "res_df['precision'] = [1,\n",
    "                  precision_score(y_true, pd_freebayes['sample_1'].astype(bool).values),\n",
    "                  precision_score(y_true, pd_freebayes['sample_2'].astype(bool).values),\n",
    "                  precision_score(y_true, pd_freebayes['sample_3'].astype(bool).values),\n",
    "                 ]\n",
    "\n",
    "res_df['recall'] = [1,\n",
    "                  recall_score(y_true, pd_freebayes['sample_1'].astype(bool).values),\n",
    "                  recall_score(y_true, pd_freebayes['sample_2'].astype(bool).values),\n",
    "                  recall_score(y_true, pd_freebayes['sample_3'].astype(bool).values),\n",
    "                 ]\n",
    "print(res_df)\n",
    "res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                var_name='metric', value_name='value')\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", #hue=\"kind\",  \n",
    "                capsize=.2, palette=\"YlGnBu_d\", height=6, aspect=.75,\n",
    "                kind=\"point\", sort= False, data=res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple method comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbersnvs_pd = pd.DataFrame.empty\n",
    "\n",
    "for si, s in enumerate([sample_0, sample_1, sample_2, sample_3]):\n",
    "    nb_snv = []\n",
    "    for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "        if si == 4:\n",
    "            si = 't'\n",
    "       # print('sample '+ str(si) + ': ', method, s[s[method] == True].shape[0])\n",
    "        nb_snv.append(s[s[method] == True].shape[0])\n",
    "    if si == 0:\n",
    "        numbersnvs_pd = pd.DataFrame.from_dict({'sample_'+ str(si): nb_snv}).T\n",
    "        numbersnvs_pd.columns = ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']\n",
    "    else:\n",
    "        numbersnvs_pd.loc['sample_'+ str(si)] = nb_snv\n",
    "\n",
    "numbersnvs_pd.plot(style='.-')\n",
    "        \n",
    "numbersnvs_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]]\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]]\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]]\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]]\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd_methods[['sample_0', 'caller']]\n",
    "y_true.index.name = 'CHROM_POS'\n",
    "y_true = y_true.groupby(['CHROM_POS'])['sample_0'].sum()\n",
    "y_true[y_true == 1] = 0\n",
    "y_true = y_true.astype(bool)\n",
    "print(y_true.shape[0])\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "    \n",
    "    y_1 = pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_1 = y_1.fillna(False)\n",
    "    y_2 = pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_2 = y_2.fillna(False)\n",
    "    y_3 = pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_3 = y_3.fillna(False)\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true.values, y_1.values),\n",
    "                      precision_score(y_true.values, y_2.values),\n",
    "                      precision_score(y_true.values, y_3.values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true.values, y_1.values),\n",
    "                      recall_score(y_true.values, y_2.values),\n",
    "                      recall_score(y_true.values, y_3.values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 liquid biopsy samples as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_pd_0_bis = read_vcf(\"../data/2015-07-31_CRC-809_030915-filter-1-0/CRC-809_030915-filter-1-0-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_0_bis['INFO'] = vcf_pd_0_bis['INFO'].apply(foo)\n",
    "vcf_pd_0_bis['freebayes'] = vcf_pd_0_bis['INFO'].str.contains('freebayes')\n",
    "vcf_pd_0_bis['vardict'] = vcf_pd_0_bis['INFO'].str.contains('vardict')\n",
    "vcf_pd_0_bis['varscan'] = vcf_pd_0_bis['INFO'].str.contains('varscan')\n",
    "vcf_pd_0_bis['mutect2'] = vcf_pd_0_bis['INFO'].str.contains('mutect2')\n",
    "vcf_pd_0_bis['strelka2'] = vcf_pd_0_bis['INFO'].str.contains('strelka2')\n",
    "vcf_pd_0_bis.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_0_bis['SNV callers'] = vcf_pd_0_bis['freebayes'].map(str) + '_' + vcf_pd_0_bis['vardict'].map(str) +  '_' + vcf_pd_0_bis['varscan'].map(str)\n",
    "\n",
    "sample_0_bis = vcf_pd_0_bis[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_0_bis['CHROM_POS'] = sample_0_bis['CHROM'].astype('str').str.cat(sample_0_bis['POS'].astype('str'),sep=\"_\")\n",
    "sample_0_bis.set_index('CHROM_POS', inplace = True)\n",
    "sample_0_bis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample0 = sample_0.copy()\n",
    "sample0['date'] = '110914'\n",
    "sample0bis = sample_0_bis.copy()\n",
    "sample0bis['date'] = '030915'\n",
    "sample_ref = pd.concat([sample0, sample0bis], join='inner')\n",
    "l1 = list(sample_ref[sample_ref['date'] == '110914'].index)\n",
    "l2 = list(sample_ref[sample_ref['date'] == '030915'].index)\n",
    "print(len(l1), len(l2))\n",
    "print(len(list(set(set(l1) ^ set(l2)))))\n",
    "print(len(list(set(set(l1) & set(l2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ref.loc[list(set(set(l1) & set(l2)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tumor reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = lambda x: pd.Series(x.split('CALLERS=')[1].split(';')[0])\n",
    "vcf_pd_t = read_vcf(\"../data/2015-07-31_NCC_CRC-809_290714-T1W/NCC_CRC-809_290714-T1W-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_t['INFO'] = vcf_pd_t['INFO'].apply(foo)\n",
    "vcf_pd_t['freebayes'] = vcf_pd_t['INFO'].str.contains('freebayes')\n",
    "vcf_pd_t['vardict'] = vcf_pd_t['INFO'].str.contains('vardict')\n",
    "vcf_pd_t['varscan'] = vcf_pd_t['INFO'].str.contains('varscan')\n",
    "vcf_pd_t['mutect2'] = vcf_pd_t['INFO'].str.contains('mutect2')\n",
    "vcf_pd_t['strelka2'] = vcf_pd_t['INFO'].str.contains('strelka2')\n",
    "vcf_pd_t.drop('INFO', axis=1)\n",
    "\n",
    "\n",
    "vcf_pd_t['SNV callers'] = vcf_pd_t['freebayes'].map(str) + '_' + vcf_pd_t['vardict'].map(str) +  '_' + vcf_pd_t['varscan'].map(str)\n",
    "\n",
    "sample_t = vcf_pd_t[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_t['CHROM_POS'] = sample_t['CHROM'].astype('str').str.cat(sample_t['POS'].astype('str'),sep=\"_\")\n",
    "sample_t.set_index('CHROM_POS', inplace = True)\n",
    "sample_t = sample_t[sample_t['CHROM'] == '22']\n",
    "sample_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(sample_t.index)\n",
    "l2 = list(sample_0.index)\n",
    "print(len(l1), len(l2))\n",
    "print(len(list(set(set(l1) & set(l2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    st = sample_t[['REF', 'ALT', 'QUAL', method]]\n",
    "    st.rename(columns = {method:'sample_t'},  inplace = True)\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]]\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]]\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]]\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]]\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([st, s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_t', 'sample_t', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_t', 'sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_t', 'sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_t'] + pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_t', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_t'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [\n",
    "        precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values),\n",
    "        precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "        precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "        precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [\n",
    "        recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values),\n",
    "        recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "        recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "        recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Histograms of true allele frequencies in each tumor sample. Note how increasing admixture increases the prevalence of low- frequency variants.\n",
    "- Benchmarking results for germline SNVs\n",
    "- Benchmarking results for somatic SNVs on exome data.\n",
    "- averaged over the four replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add fake mutations on healthy mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilution effect on 986_100215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = lambda x: pd.Series(x.split('CALLERS=')[1].split(';')[0])\n",
    "vcf_pd_0 = read_vcf(\"../data/2015-07-31_CRC-986_100215-filter-1-0/CRC-986_100215-filter-1-0-ensemble-annotated.vcf\")\n",
    "vcf_pd_1 = read_vcf(\"../data/2015-07-31_CRC-986_100215-filter-05-05/CRC-986_100215-filter-05-05-ensemble-annotated.vcf\")\n",
    "vcf_pd_2 = read_vcf(\"../data/2015-07-31_CRC-986_100215-filter-005-095/CRC-986_100215-filter-005-095-ensemble-annotated.vcf\")\n",
    "vcf_pd_3 = read_vcf(\"../data/2015-07-31_CRC-986_100215-filter-001-099/CRC-986_100215-filter-001-099-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_0['INFO'] = vcf_pd_0['INFO'].apply(foo)\n",
    "vcf_pd_0['freebayes'] = vcf_pd_0['INFO'].str.contains('freebayes')\n",
    "vcf_pd_0['vardict'] = vcf_pd_0['INFO'].str.contains('vardict')\n",
    "vcf_pd_0['varscan'] = vcf_pd_0['INFO'].str.contains('varscan')\n",
    "vcf_pd_0['mutect2'] = vcf_pd_0['INFO'].str.contains('mutect2')\n",
    "vcf_pd_0['strelka2'] = vcf_pd_0['INFO'].str.contains('strelka2')\n",
    "vcf_pd_0.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_1['INFO'] = vcf_pd_1['INFO'].apply(foo)\n",
    "vcf_pd_1['freebayes'] = vcf_pd_1['INFO'].str.contains('freebayes')\n",
    "vcf_pd_1['vardict'] = vcf_pd_1['INFO'].str.contains('vardict')\n",
    "vcf_pd_1['varscan'] = vcf_pd_1['INFO'].str.contains('varscan')\n",
    "vcf_pd_1['mutect2'] = vcf_pd_1['INFO'].str.contains('mutect2')\n",
    "vcf_pd_1['strelka2'] = vcf_pd_1['INFO'].str.contains('strelka2')\n",
    "vcf_pd_1.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_2['INFO'] = vcf_pd_2['INFO'].apply(foo)\n",
    "vcf_pd_2['freebayes'] = vcf_pd_2['INFO'].str.contains('freebayes')\n",
    "vcf_pd_2['vardict'] = vcf_pd_2['INFO'].str.contains('vardict')\n",
    "vcf_pd_2['varscan'] = vcf_pd_2['INFO'].str.contains('varscan')\n",
    "vcf_pd_2['mutect2'] = vcf_pd_2['INFO'].str.contains('mutect2')\n",
    "vcf_pd_2['strelka2'] = vcf_pd_2['INFO'].str.contains('strelka2')\n",
    "vcf_pd_2.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_3['INFO'] = vcf_pd_3['INFO'].apply(foo)\n",
    "vcf_pd_3['freebayes'] = vcf_pd_3['INFO'].str.contains('freebayes')\n",
    "vcf_pd_3['vardict'] = vcf_pd_3['INFO'].str.contains('vardict')\n",
    "vcf_pd_3['varscan'] = vcf_pd_3['INFO'].str.contains('varscan')\n",
    "vcf_pd_3['mutect2'] = vcf_pd_3['INFO'].str.contains('mutect2')\n",
    "vcf_pd_3['strelka2'] = vcf_pd_3['INFO'].str.contains('strelka2')\n",
    "vcf_pd_3.drop('INFO', axis=1)\n",
    "\n",
    "vcf_pd_0['SNV callers'] = vcf_pd_0['freebayes'].map(str) + '_' + vcf_pd_0['vardict'].map(str) +  '_' + vcf_pd_0['varscan'].map(str)\n",
    "vcf_pd_1['SNV callers'] = vcf_pd_1['freebayes'].map(str) + '_' + vcf_pd_1['vardict'].map(str) +  '_' + vcf_pd_1['varscan'].map(str)\n",
    "vcf_pd_2['SNV callers'] = vcf_pd_2['freebayes'].map(str) + '_' + vcf_pd_2['vardict'].map(str) +  '_' + vcf_pd_2['varscan'].map(str)\n",
    "vcf_pd_3['SNV callers'] = vcf_pd_3['freebayes'].map(str) + '_' + vcf_pd_3['vardict'].map(str) +  '_' + vcf_pd_3['varscan'].map(str)\n",
    "\n",
    "sample_0 = vcf_pd_0[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_0['CHROM_POS'] = sample_0['CHROM'].astype('str').str.cat(sample_0['POS'].astype('str'),sep=\"_\")\n",
    "sample_0.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_1 = vcf_pd_1[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_1['CHROM_POS'] = sample_1['CHROM'].astype('str').str.cat(sample_1['POS'].astype('str'),sep=\"_\")\n",
    "sample_1.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_2 = vcf_pd_2[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_2['CHROM_POS'] = sample_2['CHROM'].astype('str').str.cat(sample_2['POS'].astype('str'),sep=\"_\")\n",
    "sample_2.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3 = vcf_pd_3[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2', 'SNV callers']]\n",
    "sample_3['CHROM_POS'] = sample_3['CHROM'].astype('str').str.cat(sample_3['POS'].astype('str'),sep=\"_\")\n",
    "sample_3.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tf = {\n",
    "    'sample_0': 0.42,\n",
    "    'sample_1': float(list(pd.read_csv(\"../data/2015-07-31_CRC-986_100215-filter-05-05/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_2': float(list(pd.read_csv(\"../data/2015-07-31_CRC-986_100215-filter-005-095/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_3': float(list(pd.read_csv(\"../data/2015-07-31_CRC-986_100215-filter-001-099/estimated_tf.txt\").columns)[0]),\n",
    "}\n",
    "\n",
    "print(samples_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbersnvs_pd = pd.DataFrame.empty\n",
    "\n",
    "for si, s in enumerate([sample_0, sample_1, sample_2, sample_3]):\n",
    "    nb_snv = []\n",
    "    for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "        if si == 4:\n",
    "            si = 't'\n",
    "       # print('sample '+ str(si) + ': ', method, s[s[method] == True].shape[0])\n",
    "        nb_snv.append(s[s[method] == True].shape[0])\n",
    "    if si == 0:\n",
    "        numbersnvs_pd = pd.DataFrame.from_dict({'sample_'+ str(si): nb_snv}).T\n",
    "        numbersnvs_pd.columns = ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']\n",
    "    else:\n",
    "        numbersnvs_pd.loc['sample_'+ str(si)] = nb_snv\n",
    "\n",
    "numbersnvs_pd.plot(style='.-')\n",
    "        \n",
    "numbersnvs_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]]\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]]\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]]\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]]\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1] for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd_methods[['sample_0', 'caller']]\n",
    "y_true.index.name = 'CHROM_POS'\n",
    "y_true = y_true.groupby(['CHROM_POS'])['sample_0'].sum()\n",
    "y_true[y_true == 1] = 0\n",
    "y_true = y_true.astype(bool)\n",
    "print(y_true.shape[0])\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "    \n",
    "    y_1 = pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_1 = y_1.fillna(False)\n",
    "    y_2 = pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_2 = y_2.fillna(False)\n",
    "    y_3 = pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).reindex(y_true.index).squeeze()\n",
    "    y_3 = y_3.fillna(False)\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true.values, y_1.values),\n",
    "                      precision_score(y_true.values, y_2.values),\n",
    "                      precision_score(y_true.values, y_3.values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true.values, y_1.values),\n",
    "                      recall_score(y_true.values, y_2.values),\n",
    "                      recall_score(y_true.values, y_3.values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_methods = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "\n",
    "    s0 = sample_0[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s0.rename(columns = {method:'sample_0'},  inplace = True)\n",
    "    s1 = sample_1[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s1.rename(columns = {method:'sample_1'},  inplace = True)\n",
    "    s2 = sample_2[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s2.rename(columns = {method:'sample_2'},  inplace = True)\n",
    "    s3 = sample_3[['REF', 'ALT', 'QUAL', method]].reindex(list(set(set(l1) & set(l2))))\n",
    "    s3.rename(columns = {method:'sample_3'},  inplace = True)\n",
    "\n",
    "    pd_method = pd.concat([s0, s1, s2, s3], axis=1)\n",
    "\n",
    "    pd_method['REF'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1]\n",
    "                        if len(list(np.unique([i for i in list(ai) if str(i) != 'nan']))) else 'nan'\n",
    "                        for ai in list(pd_method['REF'].values)]\n",
    "    pd_method['ALT'] = [list(np.unique([i for i in list(ai) if str(i) != 'nan']))[-1]\n",
    "                        if len(list(np.unique([i for i in list(ai) if str(i) != 'nan']))) else 'nan'\n",
    "                        for ai in list(pd_method['ALT'].values)]\n",
    "    pd_method = pd_method.T.drop_duplicates().T\n",
    "    pd_method.columns = ['REF', 'ALT', 'QUAL_0', 'sample_0', 'QUAL_1', 'sample_1', 'QUAL_2', 'sample_2',  'QUAL_3', 'sample_3']\n",
    "    pd_method.head()\n",
    "\n",
    "    pd_method[['sample_0', 'sample_1', 'sample_2', 'sample_3']] = pd_method[['sample_0','sample_1', 'sample_2', 'sample_3']].fillna(value=False)\n",
    "    pd_method.drop(pd_method[pd_method['sample_0'] + pd_method['sample_1'] + pd_method['sample_2'] + pd_method['sample_3'] == False].index, axis=0, inplace=True)\n",
    "    pd_method[['REF', 'sample_0', 'sample_1', 'sample_2', 'sample_3']].head()\n",
    "    pd_method['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_methods = pd_method\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_methods = pd.concat([pd_methods, pd_method], join='inner')\n",
    "print(pd_methods.shape)\n",
    "\n",
    "pd_results = pd.DataFrame.empty\n",
    "count = 0\n",
    "\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "    print(method)\n",
    "    \n",
    "    res_df = (100*pd.Series(samples_tf)).round(decimals=2).to_frame(name='tumor burden')\n",
    "\n",
    "    y_true = pd_methods[pd_methods['caller'] == method]['sample_0'].astype(bool).values\n",
    "\n",
    "    res_df['precision'] = [1,\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      precision_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "\n",
    "    res_df['recall'] = [1,\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_1'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_2'].astype(bool).values),\n",
    "                      recall_score(y_true, pd_methods[pd_methods['caller'] == method]['sample_3'].astype(bool).values),\n",
    "                     ]\n",
    "    res_df = pd.melt(res_df, id_vars =['tumor burden'], value_vars =['precision', 'recall'],\n",
    "                    var_name='metric', value_name='value')\n",
    "    res_df['caller'] = method\n",
    "\n",
    "    if count == 0:\n",
    "        pd_results = res_df\n",
    "        count = 1\n",
    "    else:\n",
    "        pd_results = pd.concat([pd_results, res_df], join='inner')\n",
    "\n",
    "print(pd_results.head())\n",
    "print(pd_results.shape)\n",
    "\n",
    "g = sns.catplot(x=\"tumor burden\", y=\"value\", col=\"metric\", hue=\"caller\",  \n",
    "                capsize=.2, height=6, aspect=.75,\n",
    "                kind=\"point\", order=sorted(pd_results['tumor burden'].unique(), reverse=True), data=pd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
