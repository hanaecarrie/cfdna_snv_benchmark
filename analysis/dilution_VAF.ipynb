{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pysam\n",
    "from collections import Counter\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import io\n",
    "from pysam import VariantFile\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab20 = cm.get_cmap('tab10', 8)\n",
    "newcmap_list = []\n",
    "for i in range(4):\n",
    "    newcmap_list.append(tab20.colors[i])\n",
    "for i in range(4):\n",
    "    newcmap_list.append(np.array(list(tab20.colors[i][:-1]) +[0.3]))\n",
    "\n",
    "newcmap = ListedColormap(newcmap_list, name='newcmap')\n",
    "color_list = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = [l for l in f if not l.startswith('##')]\n",
    "    res = pd.read_csv(\n",
    "        io.StringIO(''.join(lines)),\n",
    "        dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str,\n",
    "               'QUAL': str, 'FILTER': str, 'INFO': str},\n",
    "        sep='\\t'\n",
    "    ).rename(columns={'#CHROM': 'CHROM'})\n",
    "    return res\n",
    "\n",
    "foo = lambda x: pd.Series(x.split('CALLERS=')[1].split(';')[0])\n",
    "foo2 = lambda x: pd.Series(x.split('TYPE=')[1].split(';')[0] if len(x.split('TYPE=')) > 1 else np.nan)\n",
    "foo3 = lambda x: pd.Series(x.split('AF=')[1].split(';')[0] if len(x.split('AF=')) > 1 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select plasma sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = '809'\n",
    "#sample = '986'\n",
    "\n",
    "if sample == '809':\n",
    "    plasmasample1 = '809_110914'\n",
    "    plasmasample2 = '809_030915'\n",
    "    tumorsample1 = '809_290714-T1W'\n",
    "elif sample == '986':\n",
    "    plasmasample1 = '986_100215'\n",
    "    plasmasample2 = '986_261016'\n",
    "    tumorsample1 = '986_100215-T1W'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SNV calls for plasma sample and matching mixed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_pd_0 = read_vcf(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-1-0/CRC-\"+plasmasample1+\"-1-0-ensemble-annotated.vcf\")\n",
    "vcf_pd_1 = read_vcf(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-1-05775/CRC-\"+plasmasample1+\"-1-05775-ensemble-annotated.vcf\")\n",
    "vcf_pd_2 = read_vcf(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-075-06738/CRC-\"+plasmasample1+\"-075-06738-ensemble-annotated.vcf\")\n",
    "vcf_pd_3 = read_vcf(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-05-07701/CRC-\"+plasmasample1+\"-05-07701-ensemble-annotated.vcf\")\n",
    "vcf_pd_4 = read_vcf(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-025-08663/CRC-\"+plasmasample1+\"-025-08663-ensemble-annotated.vcf\")\n",
    "\n",
    "vcf_pd_0['callers'] = vcf_pd_0['INFO'].apply(foo)\n",
    "vcf_pd_0['type'] = vcf_pd_0['INFO'].apply(foo2)\n",
    "vcf_pd_0['VAF'] = vcf_pd_0['INFO'].apply(foo3)\n",
    "vcf_pd_0['type'][(vcf_pd_0['type'] == 'Deletion') |  (vcf_pd_0['type'] == 'del')] = 'DEL'\n",
    "vcf_pd_0['type'][(vcf_pd_0['type'] == 'Insertion') |  (vcf_pd_0['type'] == 'ins')] = 'INS'\n",
    "vcf_pd_0['freebayes'] = vcf_pd_0['INFO'].str.contains('freebayes')\n",
    "vcf_pd_0['vardict'] = vcf_pd_0['INFO'].str.contains('vardict')\n",
    "vcf_pd_0['varscan'] = vcf_pd_0['INFO'].str.contains('varscan')\n",
    "vcf_pd_0['mutect2'] = vcf_pd_0['INFO'].str.contains('mutect2')\n",
    "vcf_pd_0['strelka2'] = vcf_pd_0['INFO'].str.contains('strelka2')\n",
    "\n",
    "vcf_pd_1['callers'] = vcf_pd_1['INFO'].apply(foo)\n",
    "vcf_pd_1['type'] = vcf_pd_1['INFO'].apply(foo2)\n",
    "vcf_pd_1['VAF'] = vcf_pd_1['INFO'].apply(foo3)\n",
    "vcf_pd_1['type'][(vcf_pd_1['type'] == 'Deletion') |  (vcf_pd_1['type'] == 'del')] = 'DEL'\n",
    "vcf_pd_1['type'][(vcf_pd_1['type'] == 'Insertion') |  (vcf_pd_1['type'] == 'ins')] = 'INS'\n",
    "vcf_pd_1['freebayes'] = vcf_pd_1['INFO'].str.contains('freebayes')\n",
    "vcf_pd_1['vardict'] = vcf_pd_1['INFO'].str.contains('vardict')\n",
    "vcf_pd_1['varscan'] = vcf_pd_1['INFO'].str.contains('varscan')\n",
    "vcf_pd_1['mutect2'] = vcf_pd_1['INFO'].str.contains('mutect2')\n",
    "vcf_pd_1['strelka2'] = vcf_pd_1['INFO'].str.contains('strelka2')\n",
    "\n",
    "vcf_pd_2['callers'] = vcf_pd_2['INFO'].apply(foo)\n",
    "vcf_pd_2['type'] = vcf_pd_2['INFO'].apply(foo2)\n",
    "vcf_pd_2['VAF'] = vcf_pd_2['INFO'].apply(foo3)\n",
    "vcf_pd_2['type'][(vcf_pd_2['type'] == 'Deletion') |  (vcf_pd_2['type'] == 'del')] = 'DEL'\n",
    "vcf_pd_2['type'][(vcf_pd_2['type'] == 'Insertion') |  (vcf_pd_2['type'] == 'ins')] = 'INS'\n",
    "vcf_pd_2['freebayes'] = vcf_pd_2['INFO'].str.contains('freebayes')\n",
    "vcf_pd_2['vardict'] = vcf_pd_2['INFO'].str.contains('vardict')\n",
    "vcf_pd_2['varscan'] = vcf_pd_2['INFO'].str.contains('varscan')\n",
    "vcf_pd_2['mutect2'] = vcf_pd_2['INFO'].str.contains('mutect2')\n",
    "vcf_pd_2['strelka2'] = vcf_pd_2['INFO'].str.contains('strelka2')\n",
    "\n",
    "vcf_pd_3['callers'] = vcf_pd_3['INFO'].apply(foo)\n",
    "vcf_pd_3['type'] = vcf_pd_3['INFO'].apply(foo2)\n",
    "vcf_pd_3['VAF'] = vcf_pd_3['INFO'].apply(foo3)\n",
    "vcf_pd_3['type'][(vcf_pd_3['type'] == 'Deletion') |  (vcf_pd_3['type'] == 'del')] = 'DEL'\n",
    "vcf_pd_3['type'][(vcf_pd_3['type'] == 'Insertion') |  (vcf_pd_3['type'] == 'ins')] = 'INS'\n",
    "vcf_pd_3['freebayes'] = vcf_pd_3['INFO'].str.contains('freebayes')\n",
    "vcf_pd_3['vardict'] = vcf_pd_3['INFO'].str.contains('vardict')\n",
    "vcf_pd_3['varscan'] = vcf_pd_3['INFO'].str.contains('varscan')\n",
    "vcf_pd_3['mutect2'] = vcf_pd_3['INFO'].str.contains('mutect2')\n",
    "vcf_pd_3['strelka2'] = vcf_pd_3['INFO'].str.contains('strelka2')\n",
    "\n",
    "vcf_pd_4['callers'] = vcf_pd_4['INFO'].apply(foo)\n",
    "vcf_pd_4['type'] = vcf_pd_4['INFO'].apply(foo2)\n",
    "vcf_pd_4['VAF'] = vcf_pd_4['INFO'].apply(foo3)\n",
    "vcf_pd_4['type'][(vcf_pd_4['type'] == 'Deletion') |  (vcf_pd_4['type'] == 'del')] = 'DEL'\n",
    "vcf_pd_4['type'][(vcf_pd_4['type'] == 'Insertion') |  (vcf_pd_4['type'] == 'ins')] = 'INS'\n",
    "vcf_pd_4['freebayes'] = vcf_pd_4['INFO'].str.contains('freebayes')\n",
    "vcf_pd_4['vardict'] = vcf_pd_4['INFO'].str.contains('vardict')\n",
    "vcf_pd_4['varscan'] = vcf_pd_4['INFO'].str.contains('varscan')\n",
    "vcf_pd_4['mutect2'] = vcf_pd_4['INFO'].str.contains('mutect2')\n",
    "vcf_pd_4['strelka2'] = vcf_pd_4['INFO'].str.contains('strelka2')\n",
    "\n",
    "sample_0 = vcf_pd_0[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'type', 'VAF', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2']]\n",
    "sample_0['CHROM_POS'] = sample_0['CHROM'].astype('str').str.cat(sample_0['POS'].astype('str'),sep=\"_\")\n",
    "sample_0.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_1 = vcf_pd_1[['CHROM', 'POS', 'REF', 'ALT', 'QUAL','type', 'VAF', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2']]\n",
    "sample_1['CHROM_POS'] = sample_1['CHROM'].astype('str').str.cat(sample_1['POS'].astype('str'),sep=\"_\")\n",
    "sample_1.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_2 = vcf_pd_2[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'type', 'VAF', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2']]\n",
    "sample_2['CHROM_POS'] = sample_2['CHROM'].astype('str').str.cat(sample_2['POS'].astype('str'),sep=\"_\")\n",
    "sample_2.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_3 = vcf_pd_3[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'type', 'VAF', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2']]\n",
    "sample_3['CHROM_POS'] = sample_3['CHROM'].astype('str').str.cat(sample_3['POS'].astype('str'),sep=\"_\")\n",
    "sample_3.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_4 = vcf_pd_4[['CHROM', 'POS', 'REF', 'ALT', 'QUAL', 'type', 'VAF', 'freebayes', 'vardict', 'varscan', 'mutect2', 'strelka2']]\n",
    "sample_4['CHROM_POS'] = sample_4['CHROM'].astype('str').str.cat(sample_4['POS'].astype('str'),sep=\"_\")\n",
    "sample_4.set_index('CHROM_POS', inplace = True)\n",
    "\n",
    "sample_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tumor fraction estimation\n",
    "samples_tf = {\n",
    "    'sample_0': float(list(pd.read_csv(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-1-0/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_1': float(list(pd.read_csv(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-1-05775/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_2': float(list(pd.read_csv(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-075-06738/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_3': float(list(pd.read_csv(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-05-07701/estimated_tf.txt\").columns)[0]),\n",
    "    'sample_4': float(list(pd.read_csv(\"../data/2015-07-31_CRC-\"+plasmasample1+\"-025-08663/estimated_tf.txt\").columns)[0]),\n",
    "}\n",
    "\n",
    "print(samples_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot VAF distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(5,1,figsize=(8, 15))\n",
    "#fig.suptitle('Dilution effect on Variant Allele Frequency (VAF) distribution')\n",
    "\n",
    "VAF = {'VAF': [], 'sample': []}\n",
    "for i, sample in enumerate([sample_0, sample_1, sample_2, sample_3, sample_4]):\n",
    "    VAF['VAF'] = VAF['VAF'] + list(sample['VAF'].astype(float).values)\n",
    "    VAF['sample'] = VAF['sample']+['sample_'+str(i) for _ in range(len(sample['VAF'].astype(float).values))]\n",
    "VAF_pd = pd.DataFrame.from_dict(VAF)\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.histplot(data=VAF_pd, x='VAF', hue=\"sample\", element=\"step\",\n",
    "             palette=sns.color_palette(\"rocket\", n_colors=5),\n",
    "             binwidth=0.02, stat=\"probability\", common_norm=False)\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5,1,figsize=(8, 15))\n",
    "fig.suptitle('Dilution effect on Variant Allele Frequency (VAF) distribution')\n",
    "\n",
    "for i, sample in enumerate([sample_0, sample_1, sample_2, sample_3, sample_4]):   \n",
    "    sns.histplot(sample['VAF'].astype(float), ax=axs[i],\n",
    "            label='sample_'+str(i)+', tf={0:.2f}%'.format(100*samples_tf['sample_'+str(i)]),\n",
    "            color=sns.color_palette(\"rocket\", n_colors=5)[i],\n",
    "            binwidth=0.02, stat=\"probability\")\n",
    "    axs[i].legend()\n",
    "    axs[i].set_ylim([0, 1])\n",
    "    axs[i].set_xlim([0, 1])\n",
    "    axs[i].axhline(y=0.5, c='grey')\n",
    "    axs[i].axhline(y=0.4, c='grey', ls='--')\n",
    "    axs[i].axhline(y=0.2, c='grey', ls='-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i, sample in enumerate([sample_0, sample_1, sample_2, sample_3, sample_4]):   \n",
    "    plt.plot(sample['POS'], sample['VAF'].astype(float), '.',\n",
    "             color=sns.color_palette(\"rocket\", n_colors=5)[i],\n",
    "             label='sample_'+str(i)+', tf={0:.2f}%'.format(100*samples_tf['sample_'+str(i)]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_sharedpos_df = pd.concat([sample_0, sample_1, sample_2, sample_3, sample_4], axis=1, join=\"outer\")\n",
    "vcf_sharedpos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roundtfvalues = [round(tf, 3) for tf in list(samples_tf.values())]\n",
    "vcf_sharedpos_df = pd.concat([sample_0, sample_1, sample_2, sample_3, sample_4], axis=1, join=\"outer\")\n",
    "print(vcf_sharedpos_df.shape)\n",
    "vcf_sharedpos_df = vcf_sharedpos_df[['VAF']].astype(float)\n",
    "vcf_sharedpos_df.columns = ['sample0 VAF', 'sample1 VAF', 'sample2 VAF', 'sample3 VAF', 'sample4 VAF']\n",
    "vcf_sharedpos_df.columns = roundtfvalues\n",
    "vcf_sharedpos_df = vcf_sharedpos_df.dropna(how='all')\n",
    "a = vcf_sharedpos_df.shape[0]\n",
    "b = vcf_sharedpos_df[vcf_sharedpos_df[roundtfvalues[0]] != vcf_sharedpos_df[roundtfvalues[1]]].shape[0]\n",
    "print(a, b, 100*b/a)\n",
    "vcf_sharedpos_diff_df = vcf_sharedpos_df[vcf_sharedpos_df.stack().groupby(level=0).nunique() > 1].T\n",
    "#print(vcf_sharedpos_diff_df.columns)\n",
    "vcf_sharedpos_diff_df = vcf_sharedpos_diff_df.T\n",
    "vcf_sharedpos_diff_df.index.name='CHROM_POS'\n",
    "#print(vcf_sharedpos_diff_df.head())\n",
    "vcf_sharedpos_diff_df['group'] = 'VAF down'\n",
    "change_index = vcf_sharedpos_diff_df[(vcf_sharedpos_diff_df[roundtfvalues[-1]].astype(float) > vcf_sharedpos_diff_df[roundtfvalues[-2]].astype(float)) |\n",
    "                                   (vcf_sharedpos_diff_df[roundtfvalues[-2]].astype(float) > vcf_sharedpos_diff_df[roundtfvalues[-3]].astype(float)) |\n",
    "                                    (vcf_sharedpos_diff_df[roundtfvalues[-3]].astype(float) > vcf_sharedpos_diff_df[roundtfvalues[-4]].astype(float)) |\n",
    "                                    (vcf_sharedpos_diff_df[roundtfvalues[-4]].astype(float) > vcf_sharedpos_diff_df[roundtfvalues[-5]].astype(float))].index\n",
    "vcf_sharedpos_diff_df['group'].loc[change_index] = 'VAF up'\n",
    "vcf_sharedpos_diff_df.reset_index(inplace=True)\n",
    "print(vcf_sharedpos_diff_df.head())\n",
    "print(vcf_sharedpos_diff_df[['group', 'CHROM_POS']].groupby(['group']).count())\n",
    "vcf_sharedpos_diff_df.drop('CHROM_POS', axis=1, inplace=True)\n",
    "vcf_sharedpos_diff_df.set_index('group', inplace=True)\n",
    "vcf_sharedpos_diff_df = vcf_sharedpos_diff_df.T\n",
    "vcf_sharedpos_diff_df.index.name='tumor burden'\n",
    "vcf_sharedpos_diff_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "vcf_sharedpos_diff_df = pd.melt(vcf_sharedpos_diff_df, id_vars =['tumor burden'], value_vars =vcf_sharedpos_diff_df.columns[1:],\n",
    "                    var_name='group', value_name='VAF')\n",
    "\n",
    "#print(vcf_sharedpos_diff_df.head())\n",
    "sns.catplot(x=\"tumor burden\", y=\"VAF\", hue='group', #hue=\"CHROM_POS\",\n",
    "            data=vcf_sharedpos_diff_df, order=sorted(list(roundtfvalues), reverse=True), kind=\"point\",\n",
    "            palette=sns.color_palette(\"husl\"))\n",
    "#vcf_sharedpos_diff_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_sharedpos_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vcf_sharedpos_diff_df.loc[vcf_sharedpos_diff_df[roundtfvalues[-1]].astype(float) > vcf_sharedpos_diff_df[roundtfvalues[-2]].astype(float)]['group'] = 'VAF up'\n",
    "vcf_sharedpos_diff_df[vcf_sharedpos_diff_df[roundtfvalues[-1]].astype(float) > vcf_sharedpos_diff_df[roundtfvalues[-2]].astype(float)]\n",
    "#vcf_sharedpos_diff_df[vcf_sharedpos_diff_df['group'] == 'VAF up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"tumor burden\", y=\"VAF\", #, hue=\"CHROM_POS\",\n",
    "            data=vcf_sharedpos_diff_df)\n",
    "vcf_sharedpos_diff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Benchmarking results for germline SNVs\n",
    "- Benchmarking results for somatic SNVs on exome data.\n",
    "- averaged over the four replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add fake mutations on healthy mixtures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
