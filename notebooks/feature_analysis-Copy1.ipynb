{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from utils.config import Config\n",
    "from featureanalysis.featureanalysis import parse_caller_feature\n",
    "from utils.config import Config\n",
    "from utils.viz import *\n",
    "from utils.table import *\n",
    "from utils.metrics import *\n",
    "from utils.calltable import *\n",
    "from utils.calltableseries import *\n",
    "from utils.groundtruth import *\n",
    "from utils.metricsseries import *\n",
    "from utils.venn import venn6, get_labels\n",
    "import random\n",
    "\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, average_precision_score, precision_score, recall_score, mean_squared_error, accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not os.getcwd().endswith('cfdna_snv_benchmark'):\n",
    "    os.chdir('../')\n",
    "print('Current working directory: {}'.format(os.getcwd()))\n",
    "\n",
    "config = Config(\"config/\", \"config_viz.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chomosome\n",
    "\n",
    "mixtureids =  ['CRC-1014_180816-CW-T_CRC-1014_090516-CW-T', 'CRC-986_100215-CW-T_CRC-986_300316-CW-T', 'CRC-123_310715-CW-T_CRC-123_121115-CW-T']\n",
    "mixtureid = 'CRC-986_100215-CW-T_CRC-986_300316-CW-T'\n",
    "#mixtureid = 'CRC-1014_180816-CW-T_CRC-1014_090516-CW-T'\n",
    "#mixtureid = 'CRC-123_310715-CW-T_CRC-123_121115-CW-T'\n",
    "reload = False\n",
    "save = False\n",
    "fixedvars=['coverage', 'ctdna']\n",
    "filterparam = 'all'\n",
    "\n",
    "markers = ['o', '^', 'X']\n",
    "linestyles = ['-', '-', '-']\n",
    "color_dict = {config.methods[i]: config.colors[i] for i in range(len(config.methods))}\n",
    "\n",
    "muttypes = ['snv', 'indel']\n",
    "metrics = ['auprc', 'precision', 'recall']\n",
    "\n",
    "chrom = 'all'\n",
    "\n",
    "print(config.methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedvar = 'coverage'\n",
    "if fixedvar == 'coverage':\n",
    "    seriesorder = [(70, 0), (70, 80), (50, 100), (30, 120), (20, 130), (10, 140), (5, 145)]\n",
    "    xaxis = 'tumor burden'\n",
    "elif fixedvar == 'ctdna':\n",
    "    seriesorder = [(70, 0), (70, 80), (70, 180)]\n",
    "    xaxis = 'coverage'\n",
    "print('############# {} ############'.format(mixtureid))\n",
    "if mixtureid ==  'CRC-1014_180816-CW-T_CRC-1014_090516-CW-T':\n",
    "    chroms = [str(c) for c in range(1,23) if c !=17 and c !=8 and c!=5 and c!=19 and c!=20 and c!=21 and c!=22]\n",
    "elif mixtureid ==  'CRC-986_100215-CW-T_CRC-986_300316-CW-T':\n",
    "    chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=8 and c!=20 and c!=21 and c!=22] \n",
    "else:\n",
    "    chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=6 and c!=20 and c!=21] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedvar = 'coverage'\n",
    "if fixedvar == 'coverage':\n",
    "    seriesorder = [(70, 0), (70, 80), (50, 100), (30, 120), (20, 130), (10, 140), (5, 145)]\n",
    "    xaxis = 'tumor burden'\n",
    "elif fixedvar == 'ctdna':\n",
    "    seriesorder = [(70, 0), (70, 80), (70, 180)]\n",
    "    xaxis = 'coverage'\n",
    "#for mixtureid in mixtureids:\n",
    "print('############# {} ############'.format(mixtureid))\n",
    "if mixtureid ==  'CRC-1014_180816-CW-T_CRC-1014_090516-CW-T':\n",
    "    chroms = [str(c) for c in range(1,23) if c !=17 and c !=8 and c!=5 and c!=19 and c!=20 and c!=21 and c!=22]\n",
    "elif mixtureid ==  'CRC-986_100215-CW-T_CRC-986_300316-CW-T':\n",
    "    chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=8 and c!=20 and c!=21 and c!=22] \n",
    "else:\n",
    "    chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=6 and c!=20 and c!=21] \n",
    "calltables = {'sampleid':[], 'tf':[], 'cov':[], 'snv':[], 'indel':[], 'snp':[]}\n",
    "aux_all = []\n",
    "calltable_snv, aux = get_calltableseries(config, mixtureid, chroms, muttype='snv', filterparam=filterparam, reload=reload, save=save)\n",
    "calltable_indel, aux = get_calltableseries(config, mixtureid, chroms, muttype='indel', filterparam=filterparam, reload=reload, save=save)\n",
    "calltable_snp, aux = get_calltableseries(config, mixtureid, chroms, muttype='snp', filterparam=filterparam, reload=reload, save=save)\n",
    "print(calltable_snv.shape, calltable_indel.shape, calltable_snp.shape)\n",
    "print(aux)\n",
    "plasmasample = '_'.join(mixtureid.split('_')[:2])\n",
    "print(plasmasample)\n",
    "healthysample = '_'.join(mixtureid.split('_')[2:])\n",
    "print(healthysample)\n",
    "calltables['snv'].append(calltable_snv)\n",
    "calltables['indel'].append(calltable_indel)\n",
    "calltables['snp'].append(calltable_snp)\n",
    "calltables['sampleid'] = mixtureid \n",
    "calltables['tf'] = np.unique([cn.split('_')[0] for cn in list(calltable_snv.columns)])[:-5].astype(float)\n",
    "calltables['snv'] = pd.concat(calltables['snv'])\n",
    "calltables['indel'] = pd.concat(calltables['indel'])\n",
    "calltables['snp'] = pd.concat(calltables['snp'])\n",
    "dilutionseries = aux.T[['mixture_' + '_'.join(mixtureid.split('_')[:2]) + '_' + str(s[0]) + 'x_' + '_'.join(mixtureid.split('_')[2:4]) + '_' + str(s[1]) + 'x' for s in seriesorder]].T\n",
    "#for muttype in muttypes:\n",
    "muttype = 'snv'\n",
    "refsample = 'undiluted'\n",
    "if muttype == 'snv':\n",
    "    gtm = 5\n",
    "else:  # elif muttype == 'indel':\n",
    "    gtm = 4\n",
    "print(max(aux['tf']))\n",
    "#if mixtureid ==  'CRC-986_100215-CW-T_CRC-986_300316-CW-T':\n",
    "#   gtm = 3\n",
    "#    refsample = 'tissue'\n",
    "#    calltablesseries  = generate_groundtruth(config, calltables[muttype], aux['tf'], ground_truth_method='tissue', muttype=muttype,\n",
    "#                                        matchedtissuepath=os.path.join('data', 'matchedtissue', 'NCC_CRC-986_100215-T1W', 'calls', 'NCC_CRC-986_100215-T1W_snv_calls_PASS_exome.csv'))\n",
    "#else:\n",
    "#   calltablesseries = generate_groundtruth(config, calltables[muttype], aux['tf'], ground_truth_method=gtm, muttype=muttype)\n",
    "calltablesseries = generate_groundtruth(config, calltables[muttype], aux['tf'], ground_truth_method=gtm, muttype=muttype,\n",
    "                                    matchedtissuepath=None, methods=['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan', 'varnet', 'abemus', 'sinvict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "calltablesseries[['truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'sinvict'\n",
    "tflist = ['{:.2f}'.format(tf) for tf in dilutionseries.tf]\n",
    "ressinvict = pd.DataFrame(columns=['precision', 'recall'])\n",
    "filters = ['1. Poisson model', '2. Minimum Read Depth filter \\n (conservative threshold: 5)', '3. Strand-bias filter\\n (default: left=0.3, right=0.7)', '4. Average position of called location\\n among all reads supporting the call',\n",
    "           '5. Signal-to-Noise ratio filter', '6. Homopolymer Regions filter']\n",
    "for thi, thresh in enumerate([4/6, 4/6, 2/6, 2/6, 5/6, 6/6]):\n",
    "    aux = pd.DataFrame(calltablesseries[[tf+ '_'+method+'_score' for tf in tflist]].stack()).reset_index()\n",
    "    aux.rename(columns={0: 'score'}, inplace=True)\n",
    "    #aux.columns = ['chrom_pos_ref_alt', 'score']\n",
    "    aux.set_index('chrom_pos_ref_alt', inplace=True)\n",
    "    aux = aux.join(calltablesseries[['truth']], on='chrom_pos_ref_alt', how='outer')\n",
    "    print(aux['truth'].value_counts())\n",
    "    print(thresh)\n",
    "    aux.loc[aux['score'] == thresh, 'score'] = True\n",
    "    aux.loc[aux['score'] != True, 'score'] = False\n",
    "    print(aux['score'].value_counts())\n",
    "    print(aux['truth'].value_counts())\n",
    "    aux = aux.astype(bool)\n",
    "    print('precision: {:.2f}'.format(precision_score(aux['truth'], aux['score'])))\n",
    "    print('recall: {:.2f}'.format(recall_score(aux['truth'], aux['score'])))\n",
    "    ressinvict.at[filters[thi], 'precision'] = precision_score(aux['truth'], aux['score'])\n",
    "    ressinvict.at[filters[thi], 'recall'] = recall_score(aux['truth'], aux['score'])\n",
    "\n",
    "\"\"\"\n",
    "    print(tf)\n",
    "    for thresh in [4/6, 2/6]:\n",
    "        print(thresh)\n",
    "        aux = calltablesseries[[tf+ '_'+method +'_score', 'truth']]\n",
    "        #print(aux[tf+ '_'+method +'_score'].value_counts())\n",
    "        aux.loc[aux[tf+ '_'+method +'_score'] == thresh, tf+ '_'+method +'_score'] = True\n",
    "        aux.loc[aux[tf+ '_'+method +'_score'] != True, tf+ '_'+method +'_score'] = False\n",
    "        #print(aux[tf+ '_'+method +'_score'].value_counts())\n",
    "        #print(aux['truth'].value_counts())\n",
    "        aux = aux.astype(bool)\n",
    "        print('precision: {:.2f}'.format(precision_score(aux['truth'], aux[tf+ '_'+method +'_score'])))\n",
    "        print('recall: {:.2f}'.format(recall_score(aux['truth'], aux[tf+ '_'+method +'_score'])))\n",
    "\"\"\"\n",
    "ressinvict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ressinvict.plot.bar(rot=90, color={\"precision\": \"purple\", \"recall\": \"tab:pink\"}, fontsize=20, figsize=(7,4))\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('SiNVICT successive filters',  fontsize=20)\n",
    "plt.ylabel('score',  fontsize=20)\n",
    "plt.ylim([0., 1])\n",
    "plt.savefig('data/featureanalysis/featureimportance_'+method+'_patient986_150x.svg')\n",
    "plt.savefig('data/featureanalysis/featureimportance_'+method+'_patient986_150x.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "random.seed(42)\n",
    "#for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan', 'abemus']: #config.methods_tissue:\n",
    "method = 'abemus'\n",
    "color_dict = {config.methods[i]: config.colors[i] for i in range(len(config.methods))}\n",
    "callmethod_snv_list = []\n",
    "for mixtureid in mixtureids:\n",
    "    #if mixtureid == 'CRC-986_100215-CW-T_CRC-986_300316-CW-T':\n",
    "    for serie in [(70, 0), (70, 80), (50, 100), (30, 120), (20, 130), (10, 140), (5, 145)]:\n",
    "        st, sn = serie\n",
    "        #print(serie)\n",
    "        if mixtureid ==  'CRC-1014_180816-CW-T_CRC-1014_090516-CW-T':\n",
    "            chroms = [str(c) for c in range(1,23) if c !=17 and c !=8 and c!=5 and c!=19 and c!=20 and c!=21 and c!=22]\n",
    "        elif mixtureid ==  'CRC-986_100215-CW-T_CRC-986_300316-CW-T':\n",
    "            chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=8 and c!=20 and c!=21 and c!=22] \n",
    "        else:\n",
    "            chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=6 and c!=20 and c!=21] \n",
    "        for chrom in chroms:\n",
    "            #print(chrom)\n",
    "            callmethod_snv, _, _ = parse_caller_feature(\n",
    "                'data/mixtures/mixtures_chr'+chrom+'/mixtures_chr'+chrom+'_'+mixtureid+'/mixture_chr'+chrom+'_'+'_'.join(mixtureid.split('_')[:2])+'_'+str(st)+'x_'+'_'.join(mixtureid.split('_')[2:])+'_'+str(sn)+'x',\n",
    "                method, save=False)\n",
    "            if method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "                callmethod_snv.drop(['ANN'], axis=1, inplace=True)\n",
    "            #print(callmethod_snv.shape)\n",
    "            #print(list(callmethod_snv.columns))\n",
    "            #print(callmethod_snv.head())\n",
    "            callmethod_snv_list.append(callmethod_snv)\n",
    "callmethod_snv_allchrom = pd.concat(callmethod_snv_list)\n",
    "\n",
    "# callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "callmethod_snv_allchrom = callmethod_snv_allchrom.join(calltablesseries[['truth']], how='outer')\n",
    "print('hello', callmethod_snv_allchrom['truth'].isna().sum(), callmethod_snv_allchrom.shape[0])\n",
    "callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "callmethod_snv_allchrom['truth'].value_counts()\n",
    "#callmethod_snv_allchrom.head()\n",
    "\n",
    "features = list(callmethod_snv_allchrom.columns)\n",
    "print(features)\n",
    "for x in [method,  method+'_vaf', 'type', 'alt', 'chrom', 'pos', 'ref', method+'_totcov', method+'_altcov', 'truth', method+'_score']:\n",
    "    print(x)\n",
    "    features.remove(x)\n",
    "print(features)\n",
    "\n",
    "#callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "callmethod_snv_allchrom['truth'].value_counts()\n",
    "callmethod_snv_allchrom[method].value_counts()\n",
    "callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] == 'PASS'] = 1\n",
    "callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] != 1] = 0\n",
    "\n",
    "forbiden_features = ['OLD_VARIANT', 'TYPE', \"cosmid_id\", 'AN', \"NS\", 'CIGAR', 'technology.illumina', 'RUN', 'END_POS_REF', 'REF_MFVdVs', 'ALT_MFVdVs', 'Sample_Name'] #AF\n",
    "score_features = ['ODDS', 'TLOD', 'SomaticEVS', 'SSF', 'SPV', 'pass.filter.pbem_coverage', 'filter.pbem_coverage', 'FALSE.']\n",
    "#print(features)\n",
    "\n",
    "Xlist = []\n",
    "for feature in features:\n",
    "    test = 0\n",
    "    try:\n",
    "        aux = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "        test = 1\n",
    "    except:\n",
    "        try: \n",
    "            aux = callmethod_snv_allchrom[feature].str.split(',').str[0].fillna(0).astype(float)\n",
    "            test = 1\n",
    "        except:\n",
    "            try:\n",
    "                aux = callmethod_snv_allchrom[feature]\n",
    "                aux[aux == '.'] = 'nan'\n",
    "                aux.fillna(0, inplace=True)\n",
    "                aux = aux.astype(float)\n",
    "                test =1\n",
    "            except:\n",
    "                test = 0\n",
    "                print(feature, 'no')\n",
    "    if test == 1 and feature not in forbiden_features and feature not in score_features:\n",
    "        print(feature, 'yes')\n",
    "        aux = aux.astype(float)\n",
    "        aux.fillna(0, inplace=True)\n",
    "        Xlist.append(aux)\n",
    "\n",
    "X = pd.concat(Xlist, axis=1)\n",
    "print(X.columns)\n",
    "if method == 'vardict':\n",
    "    X['SOR'][X['SOR'] == np.inf] = X['SOR'][X['SOR'] != np.inf].max()  # replace inf values\n",
    "y = callmethod_snv_allchrom[method+'_score'].fillna(0)\n",
    "plt.figure()\n",
    "y.plot.hist()\n",
    "plt.show()\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "print(y.describe())\n",
    "\n",
    "feature_name_dict = {}\n",
    "for i, x in enumerate(list(X.columns)):\n",
    "    feature_name_dict[i] = x\n",
    "feature_name_dict\n",
    "\n",
    "#model = DecisionTreeRegressor(random_state=0, max_depth=3)\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "#grid = {\n",
    "#        'bootstrap': [True, False],\n",
    "#        'max_depth':  [10, 25, 50, 75, 100, 200, None], #[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#        'max_features': ['auto', 'sqrt'],\n",
    "#        'min_samples_leaf': [1, 2, 4],\n",
    "#        'min_samples_split': [2, 5, 10],\n",
    "#        'n_estimators': [200, 400, 600, 800, 1000] #, 1200, 1400, 1600, 1800, 2000]\n",
    "#   }\n",
    "#model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False})\n",
    "#if method == 'strelka2':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False})\n",
    "#elif method == 'mutect2':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False})\n",
    "#elif method == 'abemus':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}) # abemus\n",
    "#else:\n",
    "#gridsearch = RandomizedSearchCV(estimator=model, param_distributions=grid, n_jobs=8, scoring=\"roc_auc\", n_iter=25, cv=5, verbose=6, random_state=0)\n",
    "#gridsearch.fit(X, y)\n",
    "#print(gridsearch.best_params_)\n",
    "# save best params\n",
    "#pd.Series(gridsearch.best_params_).to_csv('data/featureanalysis/bestparams_'+method+'_986_150x.csv')\n",
    "#model = model.set_params(**gridsearch.best_params_) # retrive best hyper params\n",
    "# save model\n",
    "#import pickle\n",
    "#with open(\"data/featureanalysis/model_\"+method+\"_986_150x.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(model, f)\n",
    "#cv = StratifiedKFold(n_splits=10, shuffle = True, random_state=0) # prepare 10-fold CV\n",
    "#for i, cvi in enumerate(cv):\n",
    "cvn = 10\n",
    "sfolder = KFold(n_splits=cvn,random_state=0,shuffle=False)\n",
    "cv_results = cross_validate(model, X, y, cv=sfolder, scoring='neg_mean_squared_error', return_estimator=True, verbose=6)\n",
    "print(cv_results['test_score'])\n",
    "print(y[y!=0].describe())\n",
    "# save cv results\n",
    "#pd.DataFrame(cv_results).to_csv('data/featureanalysis/cvresults_'+method+'_3patients_150x.csv')\n",
    "\n",
    "#model.fit(X, y)\n",
    "#ypred = model.predict(X)\n",
    "#print(sklearn.metrics.mean_squared_error(y, ypred))\n",
    "plt.rc('font', size=20) \n",
    "fi_pd_list = []\n",
    "rocauclist = []\n",
    "for idx, estimator in enumerate(cv_results['estimator']):\n",
    "    for ci, (trainindex, testindex) in enumerate(sfolder.split(X,y)):\n",
    "        if ci == c:\n",
    "            print(X.shape)\n",
    "            ypredi = pd.Series(estimator.predict([X.iloc[i,:] for i in testindex]))\n",
    "            yi = pd.Series([y[i] for i in testindex])\n",
    "            #print(cv_results['test_score'][idx], mean_squared_error(yi, ypredi))\n",
    "            thrs = 0.5\n",
    "            if method == 'smurf':\n",
    "                thrs = 0.0822\n",
    "            yi[yi >= thrs ] = 1\n",
    "            yi[yi < thrs ] = 0\n",
    "            ypredi[ypredi >= thrs ] = 1\n",
    "            ypredi[ypredi < thrs ] = 0\n",
    "            print('F1: ', f1_score(yi, ypredi))\n",
    "            print('ROC AUC: ', roc_auc_score(yi, ypredi))\n",
    "            print('Balanced accuracy: ', balanced_accuracy_score(yi, ypredi))\n",
    "            print('Accuracy: ', accuracy_score(yi, ypredi))\n",
    "            rocauclist.append(roc_auc_score(yi, ypredi))\n",
    "    c += 1\n",
    "    fi_pd = pd.DataFrame(estimator.feature_importances_,\n",
    "                         columns=['importance']).sort_values('importance', ascending=False)\n",
    "    fi_pd_list.append(fi_pd)\n",
    "print('ROC AUC = {:.2f} +/- {:.2f}'.format(np.mean(rocauclist), np.std(rocauclist)))\n",
    "feature_importances = pd.concat(fi_pd_list, axis=1)\n",
    "feature_importances.columns = ['estimator_'+str(i) for i in range(cvn)]\n",
    "feature_importances.index = feature_name_dict.values()\n",
    "feature_importances['median'] = feature_importances.median(axis=1)\n",
    "#feature_importances.to_csv('data/featureanalysis/featureimportance_df_'+method+'_3patients_150x.csv')\n",
    "feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "feature_importances = feature_importances[(feature_importances['median'] > 0.01)]\n",
    "feature_importances.sort_values(by='median', ascending=False, inplace=True)\n",
    "g = sns.catplot(data=feature_importances.T.drop('median'), kind=\"box\", color=color_dict[method],\n",
    "                height=6, aspect=3.5);\n",
    "g.map_dataframe(sns.stripplot,\n",
    "                palette=[\"k\"], dodge=True)\n",
    "g.set_xticklabels(rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "plt.title(method + ' feature importance analysis. CV MSE = {:.2E} +/- {:.2E}'.format(-np.mean(cv_results['test_score']), np.std(cv_results['test_score'])))\n",
    "#plt.savefig('data/featureanalysis/featureimportance_'+method+'_3patients_150x.svg')\n",
    "#plt.savefig('data/featureanalysis/featureimportance_'+method+'_3patients_150x.png')\n",
    "plt.show()\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "#import graphviz#\n",
    "\n",
    "#dot_data = export_graphviz(model, feature_names=X.columns, filled=True, rounded=True)  \n",
    "\n",
    "#graph = graphviz.Source(dot_data)\n",
    "#graph.render(\"tree_\"+method) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = RandomForestRegressor(random_state=0)\n",
    "#cvn = 10\n",
    "#sfolder = KFold(n_splits=cvn,random_state=0,shuffle=False)\n",
    "#cv_results = cross_validate(model, X, y, cv=sfolder, scoring='neg_mean_squared_error', return_estimator=True, verbose=6)\n",
    "#print(cv_results['test_score'])\n",
    "#print(y[y!=0].describe())\n",
    "# save cv results\n",
    "#pd.DataFrame(cv_results).to_csv('data/featureanalysis/cvresults_'+method+'_3patients_150x.csv')\n",
    "\n",
    "#model.fit(X, y)\n",
    "#ypred = model.predict(X)\n",
    "#print(sklearn.metrics.mean_squared_error(y, ypred))\n",
    "#y = y.values\n",
    "plt.rc('font', size=20) \n",
    "fi_pd_list = []\n",
    "c = 0\n",
    "rocauclist = []\n",
    "for idx, estimator in enumerate(cv_results['estimator']):\n",
    "    for ci, (trainindex, testindex) in enumerate(sfolder.split(X,y)):\n",
    "        if ci == c:\n",
    "            print(X.shape)\n",
    "            ypredi = pd.Series(estimator.predict([X.iloc[i,:] for i in testindex]))\n",
    "            yi = pd.Series([y[i] for i in testindex])\n",
    "            #print(cv_results['test_score'][idx], mean_squared_error(yi, ypredi))\n",
    "            threshold = 0.5\n",
    "            if method == 'abemus':\n",
    "                threshold = 0.5\n",
    "            yi[yi >= threshold ] = 1\n",
    "            yi[yi < threshold ] = 0\n",
    "            ypredi[ypredi >= threshold ] = 1\n",
    "            ypredi[ypredi < threshold ] = 0\n",
    "            print('F1: ', f1_score(yi, ypredi))\n",
    "            try:\n",
    "                print('ROC AUC: ', roc_auc_score(yi, ypredi))\n",
    "                rocauclist.append(roc_auc_score(yi, ypredi))\n",
    "            except:\n",
    "                rocauclist.append(np.nan)\n",
    "            print('Balanced accuracy: ', balanced_accuracy_score(yi, ypredi))\n",
    "            print('Accuracy: ', accuracy_score(yi, ypredi))\n",
    "            print(yi.sum()/yi.shape[0])\n",
    "            \n",
    "    c += 1\n",
    "    fi_pd = pd.DataFrame(estimator.feature_importances_,\n",
    "                         columns=['importance']).sort_values('importance', ascending=False)\n",
    "    fi_pd_list.append(fi_pd)\n",
    "print('ROC AUC = {:.2f} +/- {:.2f}'.format(np.mean(rocauclist), np.std(rocauclist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocauclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calltablesseries = pd.read_csv(os.path.join('data', 'mixtures_ultradeep', 'mixtures_chrall', 'mixtures_chrall_CRC-986_100215-CW-T_CRC-986_300316-CW-T' , 'calls', 'CRC-986_100215-CW-T_CRC-986_300316-CW-T_snv_calls_all.csv'), index_col=0, memory_map=True)\n",
    "#aux = pd.read_csv(os.path.join('data', 'mixtures_ultradeep', 'mixtures_chrall', 'mixtures_chrall_CRC-986_100215-CW-T_CRC-986_300316-CW-T' , 'calls', 'CRC-986_100215-CW-T_CRC-986_300316-CW-T_tf_cov.csv'),index_col=0)\n",
    "gtm = 5\n",
    "muttype = 'snv'\n",
    "refsample = 'undiluted'\n",
    "fixedvar = 'ctdna'\n",
    "if fixedvar == 'coverage':\n",
    "    seriesorder = [(1000, 0), (1000, 1000), (750, 1250), (500, 1500), (400, 1600), (200, 1800), (100, 1900)] \n",
    "    xaxis = 'tumor burden'\n",
    "elif fixedvar == 'ctdna':\n",
    "    seriesorder = [(1000, 0), (1000, 1000), (1000, 1900)]\n",
    "    xaxis = 'coverage'\n",
    "mixtureid = 'CRC-986_100215-CW-T_CRC-986_300316-CW-T'\n",
    "#dilutionseries = aux.T[['mixture_chrall_' + '_'.join(mixtureid.split('_')[:2]) + '_' + str(s[0]) + 'x_' + '_'.join(mixtureid.split('_')[2:4]) + '_' + str(s[1]) + 'x' for s in seriesorder]].T\n",
    "#calltablesseries = generate_groundtruth(config, calltablesseries, aux['tf'], ground_truth_method=gtm, muttype=muttype,\n",
    "#                                       matchedtissuepath=None, methods=['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan', 'varnet', 'abemus', 'sinvict'])\n",
    "np.random.seed(1234)\n",
    "random.seed(42)\n",
    "#for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan', 'abemus']: #config.methods_tissue:\n",
    "method = 'freebayes'\n",
    "color_dict = {config.methods[i]: config.colors[i] for i in range(len(config.methods))}\n",
    "callmethod_snv_list = []\n",
    "for mixtureid in mixtureids:\n",
    "    if mixtureid == 'CRC-986_100215-CW-T_CRC-986_300316-CW-T':\n",
    "        for serie in [(1000, 0), (1000, 1000), (750, 1250), (500, 1500), (400, 1600), (200, 1800), (100, 1900)]:\n",
    "            st, sn = serie\n",
    "            #print(serie)\n",
    "            #if mixtureid ==  'CRC-1014_180816-CW-T_CRC-1014_090516-CW-T':\n",
    "            #    chroms = [str(c) for c in range(1,23) if c !=17 and c !=8 and c!=5 and c!=19 and c!=20 and c!=21 and c!=22]\n",
    "            #elif mixtureid ==  'CRC-986_100215-CW-T_CRC-986_300316-CW-T':\n",
    "            #    chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=8 and c!=20 and c!=21 and c!=22] \n",
    "            #else:\n",
    "            #    chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=6 and c!=20 and c!=21] \n",
    "            #for chrom in chroms:\n",
    "                #print(chrom)\n",
    "            chrom = 'all'\n",
    "            callmethod_snv, _, _ = parse_caller_feature(\n",
    "                'data/mixtures_ultradeep/mixtures_chr'+chrom+'/mixtures_chr'+chrom+'_'+mixtureid+'/mixture_chr'+chrom+'_'+'_'.join(mixtureid.split('_')[:2])+'_'+str(st)+'x_'+'_'.join(mixtureid.split('_')[2:])+'_'+str(sn)+'x',\n",
    "                method, save=False)\n",
    "            if method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "                callmethod_snv.drop(['ANN'], axis=1, inplace=True)\n",
    "            #print(callmethod_snv.shape)\n",
    "            #print(list(callmethod_snv.columns))\n",
    "            #print(callmethod_snv.head())\n",
    "            callmethod_snv_list.append(callmethod_snv)\n",
    "callmethod_snv_allchrom = pd.concat(callmethod_snv_list)\n",
    "\n",
    "# callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "callmethod_snv_allchrom = callmethod_snv_allchrom.join(calltablesseries[['truth']], how='outer')\n",
    "callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "callmethod_snv_allchrom['truth'].value_counts()\n",
    "#callmethod_snv_allchrom.head()\n",
    "\n",
    "features = list(callmethod_snv_allchrom.columns)\n",
    "print(features)\n",
    "for x in [method,  method+'_vaf', 'type', 'alt', 'chrom', 'pos', 'ref', method+'_totcov', method+'_altcov', 'truth', method+'_score']:\n",
    "    print(x)\n",
    "    features.remove(x)\n",
    "print(features)\n",
    "\n",
    "#callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "callmethod_snv_allchrom['truth'].value_counts()\n",
    "\n",
    "callmethod_snv_allchrom[method].value_counts()\n",
    "callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] == 'PASS'] = 1\n",
    "callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] != 1] = 0\n",
    "\n",
    "forbiden_features = ['OLD_VARIANT', 'TYPE', \"cosmid_id\", 'AN', \"NS\", 'CIGAR', 'technology.illumina', 'RUN'] #AF\n",
    "score_features = ['ODDS', 'TLOD', 'SomaticEVS', 'SSF', 'SPV', 'pass.filter.pbem_coverage', 'filter.pbem_coverage']\n",
    "print(features)\n",
    "\n",
    "Xlist = []\n",
    "for feature in features:\n",
    "    # print(feature)\n",
    "    test = 0\n",
    "    try:\n",
    "        aux = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "        test = 1\n",
    "    except:\n",
    "        try: \n",
    "            aux = callmethod_snv_allchrom[feature].str.split(',').str[0].fillna(0).astype(float)\n",
    "            test = 1\n",
    "        except:    \n",
    "            test = 0\n",
    "    if test == 1 and feature not in forbiden_features and feature not in score_features:\n",
    "        print(feature)\n",
    "        Xlist.append(aux)\n",
    "X = pd.concat(Xlist, axis=1)\n",
    "if method == 'vardict':\n",
    "    X['SOR'][X['SOR'] == np.inf] = X['SOR'][X['SOR'] != np.inf].max()  # replace inf values\n",
    "y = callmethod_snv_allchrom[method+'_score'].fillna(0)\n",
    "plt.figure()\n",
    "y.plot.hist()\n",
    "plt.show()\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "print(y.describe())\n",
    "\n",
    "feature_name_dict = {}\n",
    "for i, x in enumerate(list(X.columns)):\n",
    "    feature_name_dict[i] = x\n",
    "feature_name_dict\n",
    "\n",
    "#model = DecisionTreeRegressor(random_state=0, max_depth=3)\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "#grid = {\n",
    "#        'bootstrap': [True, False],\n",
    "#        'max_depth':  [10, 25, 50, 75, 100, 200, None], #[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#        'max_features': ['auto', 'sqrt'],\n",
    "#        'min_samples_leaf': [1, 2, 4],\n",
    "#        'min_samples_split': [2, 5, 10],\n",
    "#        'n_estimators': [200, 400, 600, 800, 1000] #, 1200, 1400, 1600, 1800, 2000]\n",
    "#   }\n",
    "#model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False})\n",
    "#if method == 'strelka2':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False})\n",
    "#elif method == 'mutect2':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False})\n",
    "#elif method == 'abemus':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}) # abemus\n",
    "#else:\n",
    "#gridsearch = RandomizedSearchCV(estimator=model, param_distributions=grid, n_jobs=8, scoring=\"roc_auc\", n_iter=25, cv=5, verbose=6, random_state=0)\n",
    "#gridsearch.fit(X, y)\n",
    "#print(gridsearch.best_params_)\n",
    "# save best params\n",
    "#pd.Series(gridsearch.best_params_).to_csv('data/featureanalysis/bestparams_'+method+'_986_150x.csv')\n",
    "#model = model.set_params(**gridsearch.best_params_) # retrive best hyper params\n",
    "# save model\n",
    "#import pickle\n",
    "#with open(\"data/featureanalysis/model_\"+method+\"_986_150x.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(model, f)\n",
    "#cv = StratifiedKFold(n_splits=10, shuffle = True, random_state=0) # prepare 10-fold CV\n",
    "#for i, cvi in enumerate(cv):   \n",
    "cvn = 10\n",
    "cv_results = cross_validate(model, X, y, cv=cvn, scoring='neg_mean_squared_error', return_estimator=True, verbose=6)\n",
    "print(cv_results['test_score'])\n",
    "print(y[y!=0].describe())\n",
    "# save cv results\n",
    "pd.DataFrame(cv_results).to_csv('data/featureanalysis/cvresults_'+method+'_patient986_2000x.csv')\n",
    "\n",
    "#model.fit(X, y)\n",
    "#ypred = model.predict(X)\n",
    "#print(sklearn.metrics.mean_squared_error(y, ypred))\n",
    "plt.rc('font', size=20) \n",
    "fi_pd_list = []\n",
    "for idx, estimator in enumerate(cv_results['estimator']):\n",
    "    fi_pd = pd.DataFrame(estimator.feature_importances_,\n",
    "                         columns=['importance']).sort_values('importance', ascending=False)\n",
    "    fi_pd_list.append(fi_pd)\n",
    "feature_importances = pd.concat(fi_pd_list, axis=1)\n",
    "feature_importances.columns = ['estimator_'+str(i) for i in range(cvn)]\n",
    "feature_importances.index = feature_name_dict.values()\n",
    "feature_importances['median'] = feature_importances.median(axis=1)\n",
    "feature_importances.to_csv('data/featureanalysis/featureimportance_df_'+method+'_patient986_2000x.csv')\n",
    "feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "#feature_importances = feature_importances[(feature_importances['median'] > 0.01)]\n",
    "feature_importances.sort_values(by='median', ascending=False, inplace=True)\n",
    "g = sns.catplot(data=feature_importances.T.drop('median'), kind=\"box\", color=color_dict[method],\n",
    "                height=6, aspect=3.5);\n",
    "g.map_dataframe(sns.stripplot,\n",
    "                palette=[\"k\"], dodge=True)\n",
    "g.set_xticklabels(rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "plt.title(method + ' feature importance analysis. CV MSE = {:.2E} +/- {:.2E}'.format(-np.mean(cv_results['test_score']), np.std(cv_results['test_score'])))\n",
    "plt.savefig('data/featureanalysis/featureimportance_'+method+'_patient986_2000x.svg')\n",
    "plt.savefig('data/featureanalysis/featureimportance_'+method+'_patient986_2000x.png')\n",
    "plt.show()\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "#import graphviz#\n",
    "\n",
    "#dot_data = export_graphviz(model, feature_names=X.columns, filled=True, rounded=True)  \n",
    "\n",
    "#graph = graphviz.Source(dot_data)\n",
    "#graph.render(\"tree_\"+method) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.sort_values(by='median', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabledict = pd.DataFrame()\n",
    "colorlist = []\n",
    "for method in config.methods:\n",
    "    if method != 'varnet' and method != 'sinvict':\n",
    "        feature_importances = pd.read_csv('data/featureanalysis/featureimportance_df_'+method+'_3patients_150x.csv', index_col=0)\n",
    "        feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "        feature_importances.sort_values(by='median', ascending=False, inplace=True)\n",
    "        feature_importances.drop('median', axis=1, inplace=True)\n",
    "        if method == 'mutect2':\n",
    "            feature_importances = feature_importances.T[['ECNT', 'MQ', 'DP', 'NLOD', 'NALOD']].T\n",
    "        feature_importances = feature_importances.iloc[:5, :]\n",
    "        feature_importances = feature_importances.stack().reset_index().drop('level_1', axis=1)\n",
    "        feature_importances.rename(columns={'level_0': 'feature', 0: 'importance'}, inplace=True)\n",
    "        cvresults = pd.read_csv('data/featureanalysis/cvresults_'+method+'_3patients_150x.csv', index_col=0)\n",
    "        feature_importances['caller'] = method + ' \\n CV MSE = {:.2E} +/- {:.2E}'.format(-np.mean(cvresults['test_score']), np.std(cvresults['test_score']))\n",
    "        #feature_importances.index = [l +'_'+method for l in feature_importances.index]\n",
    "        #feature_importances.reset_index(inplace=True)\n",
    "        #feature_importances.rename(columns={'index': 'feature'}, inplace=True)\n",
    "        tabledict = pd.concat([tabledict, feature_importances], axis=0)\n",
    "        colorlist.append(config.colors[config.methods.index(method)])\n",
    "        \n",
    "print(colorlist)\n",
    "\n",
    "dictcol = {}\n",
    "for method in config.methods:\n",
    "    if method != 'varnet' and method != 'sinvict':\n",
    "        cvresults = pd.read_csv('data/featureanalysis/cvresults_'+method+'_3patients_150x.csv', index_col=0)\n",
    "        dictcol[method + ' \\n CV MSE = {:.2E} +/- {:.2E}'.format(-np.mean(cvresults['test_score']), np.std(cvresults['test_score']))] = config.colors[config.methods.index(method)]\n",
    "dictcol\n",
    "#g = sns.catplot(data=tabledict.T, kind=\"box\", color=colorlist, height=6, aspect=3.5);\n",
    "#g.map_dataframe(sns.stripplot, palette=[\"k\"], dodge=True)\n",
    "#g.set_xticklabels(rotation=45, ha='right')\n",
    "#plt.xlabel('Features')\n",
    "#plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "#plt.title('Feature importance analysis')\n",
    "#sns.set(font_scale=2)\n",
    "sns.reset_defaults()\n",
    "sns.set(style=\"white\", font_scale=1.5)\n",
    "g = sns.FacetGrid(tabledict, col='caller', sharex=False, col_wrap=3, height=6, aspect=1)\n",
    "g.map_dataframe(sns.boxplot, x=\"feature\", y=\"importance\", hue='caller', palette=dictcol, fliersize=0)\n",
    "g.map_dataframe(sns.stripplot, x='feature', y='importance', palette=[\"k\"], dodge=True)\n",
    "\n",
    "for ax in g.axes:\n",
    "    ax.axhline(0.1, ls='-', c='k')\n",
    "    ax.axhline(0.01, ls='--', c='k')\n",
    "    \n",
    "plt.savefig('data/featureanalysis/figure5_featureimportance_3patients_150x.svg')\n",
    "plt.savefig('data/featureanalysis/figure5_featureimportance_3patients_150x.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabledict = pd.DataFrame()\n",
    "colorlist = []\n",
    "method = 'abemus'\n",
    "for cov in ['3patients_150x', 'patient986_2000x']:\n",
    "    feature_importances = pd.read_csv('data/featureanalysis/featureimportance_df_'+method+'_'+cov+'.csv', index_col=0)\n",
    "    feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "    feature_importances.sort_values(by='median', ascending=False, inplace=True)\n",
    "    #feature_importances.drop('median', axis=1, inplace=True)\n",
    "    feature_importances = feature_importances[['median']]\n",
    "    feature_importances = feature_importances.stack().reset_index().drop('level_1', axis=1)\n",
    "    feature_importances.rename(columns={'level_0': 'feature', 0: 'importance_'+cov.split('_')[1]}, inplace=True)\n",
    "    feature_importances.set_index('feature', inplace=True)\n",
    "    cvresults = pd.read_csv('data/featureanalysis/cvresults_'+method+'_'+cov+'.csv', index_col=0)\n",
    "    #feature_importances['coverage'] = cov # + ' \\n CV MSE = {:.2E} +/- {:.2E}'.format(-np.mean(cvresults['test_score']), np.std(cvresults['test_score']))\n",
    "    #feature_importances.index = [l +'_'+method for l in feature_importances.index]\n",
    "    #feature_importances.reset_index(inplace=True)\n",
    "    #feature_importances.rename(columns={'index': 'feature'}, inplace=True)\n",
    "    tabledict = pd.concat([tabledict, feature_importances], axis=1)\n",
    "    colorlist.append(config.colors[config.methods.index(method)])\n",
    "        \n",
    "print(colorlist)\n",
    "listfeat = set(set(list(tabledict['importance_150x'].iloc[:5].index)) | set(list(tabledict['importance_2000x'].sort_values(ascending=False).iloc[:5].index)))\n",
    "#g = sns.catplot(data=tabledict.T, kind=\"box\", color=colorlist, height=6, aspect=3.5);\n",
    "#g.map_dataframe(sns.stripplot, palette=[\"k\"], dodge=True)\n",
    "#g.set_xticklabels(rotation=45, ha='right')\n",
    "#plt.xlabel('Features')\n",
    "#plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "#plt.title('Feature importance analysis')\n",
    "#sns.set(font_scale=2)\n",
    "#sns.reset_defaults()\n",
    "#sns.set(style=\"white\", font_scale=1.5)\n",
    "#g = sns.FacetGrid(tabledict, col='coverage', sharex=False, col_wrap=3, height=6, aspect=1)\n",
    "#g.map_dataframe(sns.boxplot, x=\"feature\", y=\"importance\", hue='coverage', palette=dictcol, fliersize=0)\n",
    "#g.map_dataframe(sns.stripplot, x='feature', y='importance', palette=[\"k\"], dodge=True)\n",
    "sns.scatterplot(x='importance_150x', y='importance_2000x', data=tabledict.loc[listfeat].reset_index(), style='feature', linewidth=2, s=300, fc=\"none\", ec='tab:brown')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.plot([0,1],[0,1], ls='--', c='k')\n",
    "#plt.show()\n",
    "#for ax in g.axes:\n",
    "#    ax.axhline(0.1, ls='-', c='k')\n",
    "#    ax.axhline(0.01, ls='--', c='k')\n",
    "    \n",
    "plt.savefig('data/featureanalysis/figure5_abemus_150xvs2000x.svg')\n",
    "plt.savefig('data/featureanalysis/figure5_abemus_150xvs2000x.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-constant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-finding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorlist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabledict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['SOR'][X['SOR'] != np.inf].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "#for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan', 'abemus']: #config.methods_tissue:\n",
    "method = 'abemus'\n",
    "color_dict = {config.methods[i]: config.colors[i] for i in range(len(config.methods))}\n",
    "callmethod_snv_list = []\n",
    "for mixtureid in mixtureids:\n",
    "    for serie in [(70, 0), (70, 80), (50, 100), (30, 120), (20, 130), (10, 140), (5, 145)]:\n",
    "        st, sn = serie\n",
    "        #print(serie)\n",
    "        if mixtureid ==  'CRC-1014_180816-CW-T_CRC-1014_090516-CW-T':\n",
    "            chroms = [str(c) for c in range(1,23) if c !=17 and c !=8 and c!=5 and c!=19 and c!=20 and c!=21 and c!=22]\n",
    "        elif mixtureid ==  'CRC-986_100215-CW-T_CRC-986_300316-CW-T':\n",
    "            chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=8 and c!=20 and c!=21 and c!=22] \n",
    "        else:\n",
    "            chroms = [str(c) for c in range(1,23) if c !=1 and c!= 2 and c !=6 and c!=20 and c!=21] \n",
    "        for chrom in chroms:\n",
    "            #print(chrom)\n",
    "            callmethod_snv, _, _ = parse_caller_feature(\n",
    "                'data/mixtures/mixtures_chr'+chrom+'/mixtures_chr'+chrom+'_'+mixtureid+'/mixture_chr'+chrom+'_'+'_'.join(mixtureid.split('_')[:2])+'_'+str(st)+'x_'+'_'.join(mixtureid.split('_')[2:])+'_'+str(sn)+'x',\n",
    "                method, save=False)\n",
    "            if method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "                callmethod_snv.drop(['ANN'], axis=1, inplace=True)\n",
    "            #print(callmethod_snv.shape)\n",
    "            #print(list(callmethod_snv.columns))\n",
    "            #print(callmethod_snv.head())\n",
    "            callmethod_snv_list.append(callmethod_snv)\n",
    "callmethod_snv_allchrom = pd.concat(callmethod_snv_list)\n",
    "\n",
    "# callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "callmethod_snv_allchrom = callmethod_snv_allchrom.join(calltablesseries[['truth']], how='outer')\n",
    "callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "callmethod_snv_allchrom['truth'].value_counts()\n",
    "#callmethod_snv_allchrom.head()\n",
    "\n",
    "features = list(callmethod_snv_allchrom.columns)\n",
    "print(features)\n",
    "for x in [method,  method+'_vaf', 'type', 'alt', 'chrom', 'pos', 'ref', method+'_totcov', method+'_altcov', 'truth', method+'_score']:\n",
    "    print(x)\n",
    "    features.remove(x)\n",
    "print(features)\n",
    "\n",
    "#callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "callmethod_snv_allchrom['truth'].value_counts()\n",
    "\n",
    "callmethod_snv_allchrom[method].value_counts()\n",
    "callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] == 'PASS'] = 1\n",
    "callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] != 1] = 0\n",
    "\n",
    "forbiden_features = ['OLD_VARIANT', 'TYPE', \"cosmid_id\", 'AN', \"NS\", 'CIGAR', 'technology.illumina', 'RUN'] #AF\n",
    "score_features = ['ODDS', 'TLOD', 'SomaticEVS', 'SSF', 'SPV', 'pass.filter.pbem_coverage', 'filter.pbem_coverage']\n",
    "print(features)\n",
    "\n",
    "Xlist = []\n",
    "for feature in features:\n",
    "    # print(feature)\n",
    "    test = 0\n",
    "    try:\n",
    "        aux = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "        test = 1\n",
    "    except:\n",
    "        try: \n",
    "            aux = callmethod_snv_allchrom[feature].str.split(',').str[0].fillna(0).astype(float)\n",
    "            test = 1\n",
    "        except:    \n",
    "            test = 0\n",
    "    if test == 1 and feature not in forbiden_features and feature not in score_features:\n",
    "        print(feature)\n",
    "        Xlist.append(aux)\n",
    "X = pd.concat(Xlist, axis=1)\n",
    "y = callmethod_snv_allchrom[method+'_score'].fillna(0)\n",
    "plt.figure()\n",
    "y.plot.hist()\n",
    "plt.show()\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "print(y.describe())\n",
    "\n",
    "feature_name_dict = {}\n",
    "for i, x in enumerate(list(X.columns)):\n",
    "    feature_name_dict[i] = x\n",
    "feature_name_dict\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "#model = RandomForestRegressor(random_state=0)\n",
    "#grid = {\n",
    "#        'bootstrap': [True, False],\n",
    "#        'max_depth':  [10, 25, 50, 75, 100, 200, None], #[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#        'max_features': ['auto', 'sqrt'],\n",
    "#        'min_samples_leaf': [1, 2, 4],\n",
    "#        'min_samples_split': [2, 5, 10],\n",
    "#        'n_estimators': [200, 400, 600, 800, 1000] #, 1200, 1400, 1600, 1800, 2000]\n",
    "#   }\n",
    "#model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False})\n",
    "#if method == 'strelka2':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False})\n",
    "#elif method == 'mutect2':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False})\n",
    "#elif method == 'abemus':\n",
    "#    model = model.set_params(**{'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}) # abemus\n",
    "#else:\n",
    "#gridsearch = RandomizedSearchCV(estimator=model, param_distributions=grid, n_jobs=8, scoring=\"roc_auc\", n_iter=25, cv=5, verbose=6, random_state=0)\n",
    "#gridsearch.fit(X, y)\n",
    "#print(gridsearch.best_params_)\n",
    "# save best params\n",
    "#pd.Series(gridsearch.best_params_).to_csv('data/featureanalysis/bestparams_'+method+'_986_150x.csv')\n",
    "#model = model.set_params(**gridsearch.best_params_) # retrive best hyper params\n",
    "# save model\n",
    "#import pickle\n",
    "#with open(\"data/featureanalysis/model_\"+method+\"_986_150x.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(model, f)\n",
    "#cv = StratifiedKFold(n_splits=10, shuffle = True, random_state=0) # prepare 10-fold CV\n",
    "#for i, cvi in enumerate(cv):   \n",
    "cv_results = cross_validate(model, X, y, cv=10, scoring='neg_mean_squared_error', return_estimator=True, verbose=6)\n",
    "print(cv_results['test_score'])\n",
    "print(y[y!=0].describe())\n",
    "# save cv results\n",
    "pd.DataFrame(cv_results).to_csv('data/featureanalysis/cvresults_'+method+'_3patients_150x.csv')\n",
    "\n",
    "model.fit(X, y)\n",
    "ypred = model.predict(X)\n",
    "print(sklearn.metrics.mean_squared_error(y, ypred))\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz#\n",
    "\n",
    "dot_data = export_graphviz(model, feature_names=X.columns, filled=True, rounded=True)  \n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"data/featureanalysis/tree_\"+method+'_3patients') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:.2E}'.format(sklearn.metrics.mean_squared_error(y, ypred)))\n",
    "y.describe()\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=20) \n",
    "fi_pd_list = []\n",
    "for idx, estimator in enumerate(cv_results['estimator']):\n",
    "    fi_pd = pd.DataFrame(estimator.feature_importances_,\n",
    "                         columns=['importance']).sort_values('importance', ascending=False)\n",
    "    fi_pd_list.append(fi_pd)\n",
    "feature_importances = pd.concat(fi_pd_list, axis=1)\n",
    "feature_importances.columns = ['estimator_'+str(i) for i in range(10)]\n",
    "feature_importances.index = feature_name_dict.values()\n",
    "feature_importances['median'] = feature_importances.median(axis=1)\n",
    "feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "#feature_importances = feature_importances[(feature_importances['median'] > 0.01)]\n",
    "feature_importances.sort_values(by='median', ascending=False, inplace=True)\n",
    "g = sns.catplot(data=feature_importances.T.drop('median'), kind=\"box\", color=color_dict[method],\n",
    "                height=6, aspect=3.5);\n",
    "g.map_dataframe(sns.stripplot,\n",
    "                palette=[\"k\"], dodge=True)\n",
    "g.set_xticklabels(rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "plt.title(method + ' feature importance analysis. CV MSE = {:.2E} +/- {:.2E}'.format(-np.mean(cv_results['test_score']), np.std(cv_results['test_score'])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=20) \n",
    "fi_pd_list = []\n",
    "for idx, estimator in enumerate(cv_results['estimator']):\n",
    "    fi_pd = pd.DataFrame(estimator.feature_importances_,\n",
    "                         columns=['importance']).sort_values('importance', ascending=False)\n",
    "    fi_pd_list.append(fi_pd)\n",
    "feature_importances = pd.concat(fi_pd_list, axis=1)\n",
    "feature_importances.columns = ['estimator_'+str(i) for i in range(3)]\n",
    "feature_importances.index = feature_name_dict.values()\n",
    "feature_importances['median'] = feature_importances.median(axis=1)\n",
    "feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "feature_importances = feature_importances[(feature_importances['median'] > 0.01)]\n",
    "feature_importances.sort_values(by='median', ascending=False, inplace=True)\n",
    "g = sns.catplot(data=feature_importances.T.drop('median'), kind=\"box\", color=color_dict[method],\n",
    "                height=6, aspect=3.5);\n",
    "g.map_dataframe(sns.stripplot,\n",
    "                palette=[\"k\"], dodge=True)\n",
    "g.set_xticklabels(rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "plt.title(method + ' feature importance analysis. CV MSE (acc {:.2f} +/- {:.2f})'.format(np.mean(cv_results['test_score']), np.std(cv_results['test_score'])))\n",
    "#plt.savefig('data/featureanalysis/featureimportance_'+method+'_986_150x.svg')\n",
    "#plt.savefig('data/featureanalysis/featureimportance_'+method+'_986_150x.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=20) \n",
    "fi_pd_list = []\n",
    "for idx, estimator in enumerate(cv_results['estimator']):\n",
    "    fi_pd = pd.DataFrame(estimator.feature_importances_,\n",
    "                         columns=['importance']).sort_values('importance', ascending=False)\n",
    "    fi_pd_list.append(fi_pd)\n",
    "feature_importances = pd.concat(fi_pd_list, axis=1)\n",
    "feature_importances.columns = ['estimator_'+str(i) for i in range(3)]\n",
    "feature_importances.index = feature_name_dict.values()\n",
    "feature_importances['median'] = feature_importances.median(axis=1)\n",
    "feature_importances.sort_values(by='estimator_0', ascending=False, inplace=True)\n",
    "feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "feature_importances = feature_importances[(feature_importances['median'] > 0.01)]\n",
    "g = sns.catplot(data=feature_importances.T, kind=\"box\", color=color_dict[method],\n",
    "                height=6, aspect=3.5);\n",
    "g.map_dataframe(sns.stripplot,\n",
    "                palette=[\"k\"], dodge=True)\n",
    "g.set_xticklabels(rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "plt.title(method + ' feature importance analysis. CV MSE (acc {:.2f} +/- {:.2f})'.format(np.mean(cv_results['test_score']), np.std(cv_results['test_score'])))\n",
    "#plt.savefig('data/featureanalysis/featureimportance_'+method+'_986_150x.svg')\n",
    "#plt.savefig('data/featureanalysis/featureimportance_'+method+'_986_150x.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "dot_data = export_graphviz(model, feature_names=X.columns, filled=True, rounded=True)  \n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"tree\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "feature_importances_all = []\n",
    "for method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan', 'abemus']:\n",
    "    color_dict = {config.methods[i]: config.colors[i] for i in range(len(config.methods))}\n",
    "    callmethod_snv_list = []\n",
    "    for serie in [(70, 0), (70, 80), (50, 100), (30, 120), (20, 130), (10, 140), (5, 145)]:\n",
    "        st, sn = serie\n",
    "        #print(serie)\n",
    "        for chrom in chroms:\n",
    "            #print(chrom)\n",
    "            callmethod_snv, _, _ = parse_caller_feature(\n",
    "                'data/mixtures/mixtures_chr'+chrom+'/mixtures_chr'+chrom+'_CRC-986_100215-CW-T_CRC-986_300316-CW-T/mixture_chr'+chrom+'_CRC-986_100215-CW-T_'+str(st)+'x_CRC-986_300316-CW-T_'+str(sn)+'x',\n",
    "                method, save=False)\n",
    "            if method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "                callmethod_snv.drop(['ANN'], axis=1, inplace=True)\n",
    "            #print(callmethod_snv.shape)\n",
    "            #print(list(callmethod_snv.columns))\n",
    "            #print(callmethod_snv.head())\n",
    "            callmethod_snv_list.append(callmethod_snv)\n",
    "    callmethod_snv_allchrom = pd.concat(callmethod_snv_list)\n",
    "\n",
    "    # callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "    callmethod_snv_allchrom = callmethod_snv_allchrom.join(calltablesseries[['truth']], how='outer')\n",
    "    callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "    callmethod_snv_allchrom['truth'].value_counts()\n",
    "    #callmethod_snv_allchrom.head()\n",
    "    \n",
    "    features = list(callmethod_snv_allchrom.columns)\n",
    "    print(features)\n",
    "    for x in [method, method+'_score',  method+'_vaf', 'type', 'alt', 'chrom', 'pos', 'ref', method+'_totcov', method+'_altcov']:\n",
    "        print(x)\n",
    "        features.remove(x)\n",
    "    print(features)\n",
    "\n",
    "    #callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "    callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "    callmethod_snv_allchrom['truth'].value_counts()\n",
    "\n",
    "    callmethod_snv_allchrom[method].value_counts()\n",
    "    callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] == 'PASS'] = 1\n",
    "    callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] != 1] = 0\n",
    "\n",
    "    forbiden_features = ['AF', 'OLD_VARIANT', 'TYPE', \"cosmid_id\", 'AN', \"NS\", 'CIGAR']\n",
    "    score_features = ['ODDS', 'TLOD', 'SomaticEVS', 'SSF', 'SPV']\n",
    "    print(features)\n",
    "\n",
    "    Xlist = []\n",
    "    for feature in features:\n",
    "        print(feature)\n",
    "        test = 0\n",
    "        try:\n",
    "            aux = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "            test = 1\n",
    "        except:\n",
    "            try: \n",
    "                aux = callmethod_snv_allchrom[feature].str.split(',').str[0].fillna(0).astype(float)\n",
    "                test = 1\n",
    "            except:    \n",
    "                test = 0\n",
    "        if test == 1 and feature != 'truth' and feature not in forbiden_features:\n",
    "            Xlist.append(aux)\n",
    "    X = pd.concat(Xlist, axis=1)\n",
    "    y = callmethod_snv_allchrom['truth'].fillna(0)\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    feature_name_dict = {}\n",
    "    for i, x in enumerate(list(X.columns)):\n",
    "        feature_name_dict[i] = x\n",
    "    feature_name_dict\n",
    "\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "    gridsearchbestparams = pd.read_csv('data/featureanalysis/bestparams_'+method+'_986_150x.csv', index_col=0)\n",
    "    gridsearchbestparams = gridsearchbestparams.to_dict()['0']\n",
    "    for k, v in gridsearchbestparams.items():\n",
    "        try:\n",
    "            gridsearchbestparams[k] = int(v)\n",
    "        except:\n",
    "            print(k, v)\n",
    "    model.set_params(**gridsearchbestparams) # retrive best hyper params\n",
    "    # retrieve model\n",
    "    import pickle\n",
    "    # model = pickle.load(open(\"data/featureanalysis/model_\"+method+\"_986_150x.pkl\", 'rb'))\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle = True, random_state=0) # prepare 10-fold CV\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=['roc_auc', 'average_precision'], return_estimator=True, verbose=6)\n",
    "\n",
    "    # cv results\n",
    "    print(cv_results)\n",
    "    check = pd.read_csv('data/featureanalysis/cvresults_'+method+'_986_150x.csv', index_col=0)\n",
    "    print(check)\n",
    "\n",
    "    plt.rc('font', size=20) \n",
    "    fi_pd_list = []\n",
    "    for idx, estimator in enumerate(cv_results['estimator']):\n",
    "        fi_pd = pd.DataFrame(estimator.feature_importances_,\n",
    "                             columns=['importance']).sort_values('importance', ascending=False)\n",
    "        fi_pd_list.append(fi_pd)\n",
    "    feature_importances = pd.concat(fi_pd_list, axis=1)\n",
    "    feature_importances.columns = ['estimator_'+str(i) for i in range(10)]\n",
    "    feature_importances.index = feature_name_dict.values()\n",
    "    feature_importances.sort_values(by='estimator_0', ascending=False, inplace=True)\n",
    "    feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "    feature_importances['caller'] = method\n",
    "    feature_importances['mean ROC AUC'] = np.mean(cv_results['test_roc_auc'])\n",
    "    feature_importances['std ROC AUC'] = np.std(cv_results['test_roc_auc'])\n",
    "    feature_importances_all.append(feature_importances)\n",
    "    \n",
    "feature_importances_all_pd = pd.concat(feature_importances_all)\n",
    "#g = sns.catplot(data=feature_importances.T, kind=\"box\", color=color_dict[method],\n",
    "#                height=6, aspect=3.5);\n",
    "#g.map_dataframe(sns.stripplot,\n",
    "#                palette=[\"k\"], dodge=True)\n",
    "#g.set_xticklabels(rotation=45, ha='right')\n",
    "#plt.xlabel('Features')\n",
    "#plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "#plt.title(method + ' feature importance analysis. CV ROC AUC (acc {:.2f} +/- {:.2f})'.format(np.mean(cv_results['test_roc_auc']), np.std(cv_results['test_roc_auc'])))\n",
    "#plt.savefig('data/featureanalysis/featureimportance_'+method+'_986_150x.svg')\n",
    "#plt.savefig('data/featureanalysis/featureimportance_'+method+'_986_150x.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_all_pd.to_csv('data/featureanalysis/featureimportance_allmethods_986_150x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_all_pd[feature_importances_all_pd['caller'] == method].T.iloc[:-2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in config.methods:\n",
    "    if method != 'smurf' and method != 'sinvict' and method != 'varnet':\n",
    "        print(method)\n",
    "        dg = feature_importances_all_pd[feature_importances_all_pd['caller'] == method].T.iloc[:-3,:]\n",
    "        a = (dg.median() > 0.01)\n",
    "        a = a[a == True]\n",
    "        dg = dg[a.index]\n",
    "        #maxdg = feature_importances_all_pd['caller'].value_counts().max()\n",
    "        maxdg = 24\n",
    "        cdg = a.shape[0]\n",
    "        print(cdg, cdg/maxdg)\n",
    "        if cdg/maxdg < 1:\n",
    "            g = sns.catplot(data=dg, kind=\"box\", color=color_dict[method], width=0.8, height=6, aspect=3.5*cdg/maxdg+0.5);\n",
    "        else:\n",
    "            g = sns.catplot(data=dg, kind=\"box\", color=color_dict[method], width=0.8, height=6, aspect=3.5);\n",
    "        g.map_dataframe(sns.stripplot, palette=[\"k\"], dodge=True)\n",
    "        g.set_xticklabels(rotation=45, ha='right')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "        plt.title(method + ' feature importance analysis. CV ROC AUC (acc {:.2f} +/- {:.2f})'.format(np.mean(cv_results['test_roc_auc']), np.std(cv_results['test_roc_auc'])))\n",
    "        plt.ylim([0, dg.max().max()+0.01])\n",
    "        plt.savefig('data/featureanalysis/featureimportance_'+method+'_986_150x.svg')\n",
    "        plt.savefig('data/featureanalysis/featureimportance_'+method+'_986_150x.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "for method in [ 'abemus', 'varscan']: #config.methods_tissue: 'freebayes', 'mutect2', 'strelka2', 'vardict',\n",
    "    # method = 'varnet'\n",
    "    color_dict = {config.methods[i]: config.colors[i] for i in range(len(config.methods))}\n",
    "    callmethod_snv_list = []\n",
    "    for serie in [(70, 0), (70, 80), (50, 100), (30, 120), (20, 130), (10, 140), (5, 145)]:\n",
    "        st, sn = serie\n",
    "        #print(serie)\n",
    "        for chrom in chroms:\n",
    "            #print(chrom)\n",
    "            callmethod_snv, _, _ = parse_caller_feature(\n",
    "                'data/mixtures/mixtures_chr'+chrom+'/mixtures_chr'+chrom+'_CRC-986_100215-CW-T_CRC-986_300316-CW-T/mixture_chr'+chrom+'_CRC-986_100215-CW-T_'+str(st)+'x_CRC-986_300316-CW-T_'+str(sn)+'x',\n",
    "                method, save=False)\n",
    "            if method in ['freebayes', 'mutect2', 'strelka2', 'vardict', 'varscan']:\n",
    "                callmethod_snv.drop(['ANN'], axis=1, inplace=True)\n",
    "            #print(callmethod_snv.shape)\n",
    "            #print(list(callmethod_snv.columns))\n",
    "            #print(callmethod_snv.head())\n",
    "            callmethod_snv_list.append(callmethod_snv)\n",
    "    callmethod_snv_allchrom = pd.concat(callmethod_snv_list)\n",
    "\n",
    "    # callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "    callmethod_snv_allchrom = callmethod_snv_allchrom.join(calltablesseries[['truth']], how='outer')\n",
    "    callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "    callmethod_snv_allchrom['truth'].value_counts()\n",
    "    #callmethod_snv_allchrom.head()\n",
    "\n",
    "    features = list(callmethod_snv_allchrom.columns)\n",
    "    print(features)\n",
    "    for x in [method, method+'_score',  method+'_vaf', 'type', 'alt', 'chrom', 'pos', 'ref', method+'_totcov', method+'_altcov']:\n",
    "        print(x)\n",
    "        features.remove(x)\n",
    "    print(features)\n",
    "\n",
    "    #callmethod_snv_allchrom = pd.concat([callmethod_snv_allchrom, calltablesseries['truth']], axis=1)\n",
    "    callmethod_snv_allchrom['truth'].fillna(False, inplace=True)\n",
    "    callmethod_snv_allchrom['truth'].value_counts()\n",
    "\n",
    "    callmethod_snv_allchrom[method].value_counts()\n",
    "    callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] == 'PASS'] = 1\n",
    "    callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] != 1] = 0\n",
    "\n",
    "    forbiden_features = ['AF', 'OLD_VARIANT', 'TYPE', \"cosmid_id\", 'AN', \"NS\", 'CIGAR']\n",
    "    score_features = ['ODDS', 'TLOD', 'SomaticEVS', 'SSF', 'SPV']\n",
    "    print(features)\n",
    "\n",
    "    Xlist = []\n",
    "    for feature in features:\n",
    "        print(feature)\n",
    "        test = 0\n",
    "        try:\n",
    "            aux = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "            test = 1\n",
    "        except:\n",
    "            try: \n",
    "                aux = callmethod_snv_allchrom[feature].str.split(',').str[0].fillna(0).astype(float)\n",
    "                test = 1\n",
    "            except:    \n",
    "                test = 0\n",
    "        if test == 1 and feature != 'truth' and feature not in forbiden_features:\n",
    "            Xlist.append(aux)\n",
    "    X = pd.concat(Xlist, axis=1)\n",
    "    y = callmethod_snv_allchrom['truth'].fillna(0)\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    feature_name_dict = {}\n",
    "    for i, x in enumerate(list(X.columns)):\n",
    "        feature_name_dict[i] = x\n",
    "    feature_name_dict\n",
    "\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "    best_params = pd.read_csv('data/featureanalysis/bestparams_'+method+'_986_150x.csv', index_col=0).squeeze().to_dict()\n",
    "    for k, v in best_params.items():\n",
    "        try:\n",
    "            best_params[k] = int(v)\n",
    "        except:\n",
    "            print(k, v)\n",
    "    print(best_params)\n",
    "    model = model.set_params(**best_params) # retrive best hyper params\n",
    "    # save model\n",
    "    import pickle\n",
    "    #with open(\"data/featureanalysis/model_\"+method+\"_986_150x.pkl\", \"wb\") as f:\n",
    "    #    pickle.dump(model, f)\n",
    "    # read pickled model\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle = True, random_state=0) # prepare 10-fold CV\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=['roc_auc', 'average_precision'], return_estimator=True, verbose=6)\n",
    "\n",
    "    # save cv results\n",
    "    cv_results_check = pd.read_csv('data/featureanalysis/cvresults_'+method+'_986_150x.csv', index_col=0)\n",
    "    print(cv_results_check)\n",
    "\n",
    "    plt.rc('font', size=20) \n",
    "    fi_pd_list = []\n",
    "    for idx, estimator in enumerate(cv_results['estimator']):\n",
    "        fi_pd = pd.DataFrame(estimator.feature_importances_,\n",
    "                             columns=['importance']).sort_values('importance', ascending=False)\n",
    "        fi_pd_list.append(fi_pd)\n",
    "    feature_importances = pd.concat(fi_pd_list, axis=1)\n",
    "    feature_importances.columns = ['estimator_'+str(i) for i in range(10)]\n",
    "    feature_importances.index = feature_name_dict.values()\n",
    "    feature_importances.sort_values(by='estimator_0', ascending=False, inplace=True)\n",
    "    feature_importances = feature_importances[(feature_importances.T != 0).any()]\n",
    "    print(round(100*feature_importances.T.median(), 2))\n",
    "    g = sns.catplot(data=feature_importances.T, kind=\"box\", color=color_dict[method],\n",
    "                    height=6, aspect=3.5);\n",
    "    g.map_dataframe(sns.stripplot,\n",
    "                    palette=[\"k\"], dodge=True)\n",
    "    g.set_xticklabels(rotation=45, ha='right')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Feature importance in Random Forest models in CV')\n",
    "    plt.title(method + ' feature importance analysis. CV ROC AUC (acc {:.2f} +/- {:.2f})'.format(np.mean(cv_results['test_roc_auc']), np.std(cv_results['test_roc_auc'])))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = round(100*feature_importances.T.median(), 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "callmethod_snv_allchrom[method].value_counts()\n",
    "callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] == 'PASS'] = 1\n",
    "callmethod_snv_allchrom[method][callmethod_snv_allchrom[method] != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "forbiden_features = ['AF', 'OLD_VARIANT', 'TYPE', \"cosmid_id\", 'AN', \"NS\", 'CIGAR']\n",
    "score_features = ['ODDS', 'TLOD', 'SomaticEVS', 'SSF', 'SPV']\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplots(figsize=(10,10))\n",
    "plt.rc('font', size=20) \n",
    "for feature in features:\n",
    "    print(feature)\n",
    "    test = 0\n",
    "    try:\n",
    "        pred = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "        test = 1\n",
    "    except:\n",
    "        try: \n",
    "            pred = callmethod_snv_allchrom[feature].str.split(',').str[0].fillna(0).astype(float)\n",
    "            test = 1\n",
    "        except:    \n",
    "            test = 0\n",
    "    if test == 1 and feature != 'truth' and feature not in forbiden_features:\n",
    "        print('hello')\n",
    "        #pred = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "        fpr, tpr, _ = roc_curve(callmethod_snv_allchrom['truth'].fillna(0), pred)\n",
    "        if auc(fpr, tpr) < 0.5:\n",
    "            print('invert')\n",
    "            pred = -pred\n",
    "        fpr, tpr, _ = roc_curve(callmethod_snv_allchrom['truth'].fillna(0), pred)\n",
    "        print(auc(fpr, tpr))\n",
    "        if auc(fpr, tpr) >= 0.9 and feature not in score_features:\n",
    "            plot_roc_curve(fpr, tpr, estimator_name=feature, auc_score=auc(fpr, tpr), figax=ax, kwargs={'color':'r', 'lw': 3})\n",
    "        if feature in score_features:\n",
    "            plot_roc_curve(fpr, tpr, estimator_name=feature, auc_score=auc(fpr, tpr), figax=ax, kwargs={'color':'b', 'lw': 3})\n",
    "        else:\n",
    "            plot_roc_curve(fpr, tpr, estimator_name=None, auc_score=None, figax=ax, kwargs={'color':'grey', 'alpha': 0.5})\n",
    "plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "plt.title('ROC curve of each feature of caller {}'.format(method))\n",
    "#plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure()\n",
    "#ax = plt.subplots(figsize=(15,15))\n",
    "#features = ['ODDS', 'AN']\n",
    "##for feature in features:\n",
    "#    precision, recall, _ = precision_recall_curve(concatres['truth'], concatres[feature])\n",
    "#    #plt_pr_curve(fpr, tpr, estimator_name=feature, auc_score=auc(fpr, tpr), figax=ax)\n",
    "#    plot_pr_curve(precision, recall, estimator_name=feature, f1_score=average_precision_score(concatres['truth'], concatres[feature]), figax=ax, kwargs={})\n",
    "#    plt.ylim([-0.01,1.01])\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "ax = plt.subplots(figsize=(15,15))\n",
    "for feature in features:\n",
    "    print(feature)\n",
    "    test = 0\n",
    "    try:\n",
    "        pred = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "        test = 1\n",
    "    except:\n",
    "        test = 0\n",
    "    if test == 1:\n",
    "        print('hello')\n",
    "        pred = callmethod_snv_allchrom[feature].fillna(0).astype(float)\n",
    "        precision, recall, _ = precision_recall_curve(callmethod_snv_allchrom['freebayes'].fillna(0), pred)\n",
    "        fpr, tpr, _ = roc_curve(callmethod_snv_allchrom['freebayes'].fillna(0), pred)\n",
    "        if auc(fpr, tpr) < 0.5:\n",
    "            print('invert')\n",
    "            pred = -pred\n",
    "        precision, recall, _ = precision_recall_curve(callmethod_snv_allchrom['freebayes'].fillna(0), pred)\n",
    "        print(auc(fpr, tpr))\n",
    "        if auc(fpr, tpr) >= 0.9 or feature == 'ODDS':\n",
    "            plot_pr_curve(precision, recall, estimator_name=feature, f1_score=average_precision_score(callmethod_snv_allchrom['freebayes'].fillna(0), pred), figax=ax,  kwargs={'color':'r', 'lw': 3})\n",
    "        else:\n",
    "            plot_pr_curve(precision, recall, estimator_name=None, f1_score=None, figax=ax,  kwargs={'color':'grey', 'alpha': 0.5})\n",
    "plt.ylim([-0.01,1.01])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(callmethod_snv_allchrom['truth'], callmethod_snv_allchrom['freebayes_score'].fillna(0).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-christian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
